[
 {
  "link": "/papers/2403.15371",
  "id": "2403.15371",
  "title": "Can large language models explore in-context?",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15371.png"
 },
 {
  "link": "/papers/2403.15042",
  "id": "2403.15042",
  "title": "LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15042.png"
 },
 {
  "link": "/papers/2403.14781",
  "id": "2403.14781",
  "title": "Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.14781.png"
 },
 {
  "link": "/papers/2403.15383",
  "id": "2403.15383",
  "title": "ThemeStation: Generating Theme-Aware 3D Assets from Few Exemplars",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15383.png"
 },
 {
  "link": "/papers/2403.15377",
  "id": "2403.15377",
  "title": "InternVideo2: Scaling Video Foundation Models for Multimodal Video Understanding",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15377.png"
 },
 {
  "link": "/papers/2403.15382",
  "id": "2403.15382",
  "title": "DragAPart: Learning a Part-Level Motion Prior for Articulated Objects",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15382.png"
 },
 {
  "link": "/papers/2403.15360",
  "id": "2403.15360",
  "title": "SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15360.png"
 },
 {
  "link": "/papers/2403.14773",
  "id": "2403.14773",
  "title": "StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.14773.png"
 },
 {
  "link": "/papers/2403.14870",
  "id": "2403.14870",
  "title": "VidLA: Video-Language Alignment at Scale",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.14870.png"
 },
 {
  "link": "/papers/2403.15246",
  "id": "2403.15246",
  "title": "FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15246.png"
 },
 {
  "link": "/papers/2403.15385",
  "id": "2403.15385",
  "title": "LATTE3D: Large-scale Amortized Text-To-Enhanced3D Synthesis",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15385.png"
 },
 {
  "link": "/papers/2403.15157",
  "id": "2403.15157",
  "title": "AllHands: Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.15157.png"
 },
 {
  "link": "/papers/2403.14714",
  "id": "2403.14714",
  "title": "Compiler generated feedback for Large Language Models",
  "media_type": "image",
  "media_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2403.14714.png"
 }
]