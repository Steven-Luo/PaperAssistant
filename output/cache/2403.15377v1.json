{
  "id": "2403.15377v1",
  "title": "InternVideo2: Scaling Video Foundation Models for Multimodal Video Understanding",
  "pdf_url": "http://arxiv.org/pdf/2403.15377v1",
  "raw_tldr": "动机\t我们介绍了InternVideo2，这是一种新的视频基础模型（ViFM），旨在解决动作识别、视频-文本任务和以视频为中心的对话中的性能挑战。\n方法\t我们的方法采用了一种渐进式训练范式，该范式统一了不同的自监督或弱监督学习框架，包括掩蔽视频令牌重构、跨模态对比学习和下一个令牌预测。在数据层面，通过语义分割视频和生成视频-音频-语音字幕来优先考虑时空一致性，从而改善视频和文本之间的对齐。\n结果\t通过大量实验，我们验证了我们的设计，并在60多个视频和音频任务上展示了最先进的性能。特别是，我们的模型在各种视频相关的字幕、对话和长视频理解基准测试中胜过其他模型，凸显了其推理和理解长时间上下文的能力。",
  "tldr": {
    "动机": "我们介绍了InternVideo2，这是一种新的视频基础模型（ViFM），旨在解决动作识别、视频-文本任务和以视频为中心的对话中的性能挑战。",
    "方法": "我们的方法采用了一种渐进式训练范式，该范式统一了不同的自监督或弱监督学习框架，包括掩蔽视频令牌重构、跨模态对比学习和下一个令牌预测。在数据层面，通过语义分割视频和生成视频-音频-语音字幕来优先考虑时空一致性，从而改善视频和文本之间的对齐。",
    "结果": "通过大量实验，我们验证了我们的设计，并在60多个视频和音频任务上展示了最先进的性能。特别是，我们的模型在各种视频相关的字幕、对话和长视频理解基准测试中胜过其他模型，凸显了其推理和理解长时间上下文的能力。"
  },
  "summary_cn": "我们介绍了InternVideo2，一种新的视频基础模型（ViFM），在动作识别、视频-文本任务和以视频为中心的对话中实现了最先进的性能。我们的方法采用了一种渐进式训练范式，统一了不同的自我或弱监督学习框架，包括掩码视频令牌重构、跨模态对比学习和下一令牌预测。不同的训练阶段将通过不同的前置任务引导我们的模型捕捉不同层次的结构和语义信息。在数据层面，我们通过语义分割视频并生成视频-音频-语音字幕来优先考虑时空一致性。这改善了视频和文本之间的对齐。我们对InternVideo2的数据和模型大小进行了扩展。通过广泛的实验，我们验证了我们的设计，并在60多个视频和音频任务上展示了最先进的性能。值得注意的是，我们的模型在各种视频相关的字幕、对话和长视频理解基准测试中表现优于其他模型，凸显了其推理和理解长时间上下文的能力。代码和模型可在 https://github.com/OpenGVLab/InternVideo2/ 获取。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"视频基础模型\",\n    \"行动识别\",\n    \"视频文本任务\",\n    \"视频中心对话\",\n    \"自监督学习\",\n    \"跨模态对比学习\",\n    \"视频音频字幕\",\n    \"长视频理解\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "视频基础模型",
      "行动识别",
      "视频文本任务",
      "视频中心对话",
      "自监督学习",
      "跨模态对比学习",
      "视频音频字幕",
      "长视频理解"
    ]
  }
}