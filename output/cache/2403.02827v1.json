{
  "id": "2403.02827v1",
  "title": "Tuning-Free Noise Rectification for High Fidelity Image-to-Video Generation",
  "pdf_url": "http://arxiv.org/pdf/2403.02827v1",
  "raw_tldr": "动机\t图像到视频（I2V）生成任务在开放领域中始终难以保持高保真度。传统的图像动画技术主要关注特定领域，如面部或人体姿势，难以泛化到开放领域。最近基于扩散模型的几种I2V框架能为开放领域图像生成动态内容，但未能维持保真度。\n方法\t提出了一种有效的方法，可以应用于主流视频扩散模型，通过补充更精确的图像信息和噪声校正来实现高保真度。具体来说，给定一个指定的图像，我们的方法首先向输入图像的潜在表示添加噪声以保留更多细节，然后用适当的校正去噪这些带噪声的潜在表示，以减轻噪声预测偏差。\n结果\t实验结果证明了我们的方法在提高生成视频的保真度方面的有效性。",
  "tldr": {
    "动机": "图像到视频（I2V）生成任务在开放领域中始终难以保持高保真度。传统的图像动画技术主要关注特定领域，如面部或人体姿势，难以泛化到开放领域。最近基于扩散模型的几种I2V框架能为开放领域图像生成动态内容，但未能维持保真度。",
    "方法": "提出了一种有效的方法，可以应用于主流视频扩散模型，通过补充更精确的图像信息和噪声校正来实现高保真度。具体来说，给定一个指定的图像，我们的方法首先向输入图像的潜在表示添加噪声以保留更多细节，然后用适当的校正去噪这些带噪声的潜在表示，以减轻噪声预测偏差。",
    "结果": "实验结果证明了我们的方法在提高生成视频的保真度方面的有效性。"
  },
  "summary_cn": "图像到视频（I2V）生成任务在开放领域中始终难以保持高保真度。传统的图像动画技术主要关注于特定领域，如面部或人体姿势，使它们难以泛化到开放领域。基于扩散模型的几种最近的I2V框架能够为开放领域图像生成动态内容，但未能维持保真度。我们发现，低保真度的两个主要因素是图像细节的丢失和去噪过程中的噪声预测偏差。为此，我们提出了一种可以应用于主流视频扩散模型的有效方法。该方法基于补充更精确的图像信息和噪声矫正来实现高保真度。具体来说，给定一个指定的图像，我们的方法首先向输入图像的潜在表示添加噪声以保留更多细节，然后对带噪潜在表示进行适当的矫正去噪，以减轻噪声预测偏差。我们的方法无需调整，即插即用。实验结果证明了我们的方法在提高生成视频的保真度方面的有效性。欲了解更多图像到视频的生成结果，请参考项目网站：https://noise-rectification.github.io。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"CV\",\n  \"标签\": [\"Image-to-Video Generation\", \"Diffusion Models\", \"High Fidelity\", \"Noise Rectification\", \"Open Domains\"]\n}\n```",
  "tag_info": {
    "主要领域": "CV",
    "标签": [
      "Image-to-Video Generation",
      "Diffusion Models",
      "High Fidelity",
      "Noise Rectification",
      "Open Domains"
    ]
  }
}