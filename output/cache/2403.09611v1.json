{
  "id": "2403.09611v1",
  "title": "MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training",
  "pdf_url": "http://arxiv.org/pdf/2403.09611v1",
  "raw_tldr": "动机\t在本工作中，我们讨论构建高性能的多模态大型语言模型（MLLMs），特别是研究各种架构组件和数据选择的重要性。\n方法\t通过对图像编码器、视觉语言连接器和各种预训练数据选择进行仔细和全面的消融研究，我们确定了几个关键的设计经验。\n结果\t我们展示了对于大规模多模态预训练，使用精心混合的图像-标题、交错的图像-文本和仅文本数据对于在多个基准上实现最先进的少样本结果至关重要，与其他已发布的预训练结果相比。此外，我们还展示了图像编码器以及图像分辨率和图像令牌计数具有重大影响，而视觉-语言连接器设计的重要性相对较小。通过扩大所呈现的配方，我们构建了MM1，一个多模态模型家族，最多达到30B参数，包括密集模型和专家混合（MoE）变体，这些模型在预训练指标中处于最先进的水平，并在一系列既定的多模态基准上进行监督式微调后达到了有竞争力的性能。得益于大规模预训练，MM1具有吸引人的特性，如增强的上下文学习能力和多图像推理能力，使其能够进行少样本链式思维提示。",
  "tldr": {
    "动机": "在本工作中，我们讨论构建高性能的多模态大型语言模型（MLLMs），特别是研究各种架构组件和数据选择的重要性。",
    "方法": "通过对图像编码器、视觉语言连接器和各种预训练数据选择进行仔细和全面的消融研究，我们确定了几个关键的设计经验。",
    "结果": "我们展示了对于大规模多模态预训练，使用精心混合的图像-标题、交错的图像-文本和仅文本数据对于在多个基准上实现最先进的少样本结果至关重要，与其他已发布的预训练结果相比。此外，我们还展示了图像编码器以及图像分辨率和图像令牌计数具有重大影响，而视觉-语言连接器设计的重要性相对较小。通过扩大所呈现的配方，我们构建了MM1，一个多模态模型家族，最多达到30B参数，包括密集模型和专家混合（MoE）变体，这些模型在预训练指标中处于最先进的水平，并在一系列既定的多模态基准上进行监督式微调后达到了有竞争力的性能。得益于大规模预训练，MM1具有吸引人的特性，如增强的上下文学习能力和多图像推理能力，使其能够进行少样本链式思维提示。"
  },
  "summary_cn": "在这项工作中，我们讨论了构建高性能的多模态大型语言模型（MLLMs）。特别是，我们研究了各种架构组件和数据选择的重要性。通过对图像编码器、视觉语言连接器以及各种预训练数据选择的仔细和全面的消融研究，我们确定了几个关键的设计经验。例如，我们展示了对于大规模多模态预训练，使用精心混合的图像-标题、交错的图像-文本和仅文本数据对于在多个基准测试中实现最先进（SOTA）的小样本结果至关重要，与其他已发布的预训练结果相比。此外，我们展示了图像编码器以及图像分辨率和图像令牌数量具有重大影响，而视觉-语言连接器设计的重要性相对可以忽略。通过扩大所呈现的配方，我们构建了MM1，一个多模态模型家族，包括多达30B参数的密集模型和专家混合（MoE）变体，它们在预训练指标中处于最先进的水平，并在一系列既定的多模态基准测试中经过监督微调后达到了有竞争力的性能。得益于大规模预训练，MM1具有吸引人的特性，如增强的上下文学习能力和多图像推理能力，使其能够进行少样本的思维链提示。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"Multimodal Large Language Models\",\n    \"architecture components\",\n    \"data choices\",\n    \"image encoder\",\n    \"vision language connector\",\n    \"pre-training\",\n    \"state-of-the-art\",\n    \"few-shot results\",\n    \"image resolution\",\n    \"image token count\",\n    \"mixture-of-experts\",\n    \"in-context learning\",\n    \"multi-image reasoning\",\n    \"chain-of-thought prompting\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "Multimodal Large Language Models",
      "architecture components",
      "data choices",
      "image encoder",
      "vision language connector",
      "pre-training",
      "state-of-the-art",
      "few-shot results",
      "image resolution",
      "image token count",
      "mixture-of-experts",
      "in-context learning",
      "multi-image reasoning",
      "chain-of-thought prompting"
    ]
  }
}