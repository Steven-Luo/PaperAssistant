{
  "id": "2403.16990v1",
  "title": "Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation",
  "pdf_url": "http://arxiv.org/pdf/2403.16990v1",
  "raw_tldr": "动机：本研究旨在解决文本到图像扩散模型在处理包含多个主题的复杂输入提示时，常常难以准确捕捉预期语义的问题。特别是当处理多个语义或视觉上相似的主题时，这些模型往往会产生语义不准确的图像。\n\n方法：为了解决这些问题，研究者引入了一种无需训练的方法——有界注意力（Bounded Attention），该方法通过限制采样过程中的信息流动来防止主题间的不利语义泄露。有界注意力通过引导生成过程，增强每个主题的个体性，即使在复杂的多主题条件下也能保持如此。\n\n结果：通过广泛的实验，研究者证明了他们的方法能够使得生成的多个主题更好地符合给定的提示和布局，从而提升了图像生成的质量。",
  "tldr": {
    "动机：本研究旨在解决文本到图像扩散模型在处理包含多个主题的复杂输入提示时，常常难以准确捕捉预期语义的问题。特别是当处理多个语义或视觉上相似的主题时，这些模型往往会产生语义不准确的图像。": "",
    "方法：为了解决这些问题，研究者引入了一种无需训练的方法——有界注意力（Bounded Attention），该方法通过限制采样过程中的信息流动来防止主题间的不利语义泄露。有界注意力通过引导生成过程，增强每个主题的个体性，即使在复杂的多主题条件下也能保持如此。": "",
    "结果：通过广泛的实验，研究者证明了他们的方法能够使得生成的多个主题更好地符合给定的提示和布局，从而提升了图像生成的质量。": "",
    "动机": "",
    "方法": "",
    "结果": ""
  },
  "summary_cn": "文本到图像的扩散模型具有前所未有的能力，能够生成多样化和高质量的图像。然而，它们通常难以忠实地捕捉包含多个主题的复杂输入提示的预期语义。最近，为了提高用户控制，引入了许多布局到图像的扩展方法，旨在定位由特定标记表示的主题。然而，这些方法在处理多个语义上或视觉上相似的主题时，往往会产生语义上不准确的图像。在这项工作中，我们研究并分析了这些限制的原因。我们的探索揭示了主要问题源于去噪过程中主题间不经意的语义泄漏。这种泄漏归因于扩散模型的注意力层，它们倾向于混合不同主题的视觉特征。为了解决这些问题，我们引入了有界注意力（Bounded Attention），这是一种无需训练即可限制采样过程中信息流动的方法。有界注意力防止了主题间的有害泄漏，并使得即使在复杂的多主题条件下，也能够引导生成过程以促进每个主题的个性。通过广泛的实验，我们证明了我们的方法能够使生成的多个主题更好地符合给定的提示和布局。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"CV\",\n  \"标签\": [\"文本到图像生成\", \"扩散模型\", \"多主体图像生成\", \"语义泄露\", \"注意力机制\", \"信息流控制\", \"图像多样性\", \"用户控制\"]\n}\n```",
  "tag_info": {
    "主要领域": "CV",
    "标签": [
      "文本到图像生成",
      "扩散模型",
      "多主体图像生成",
      "语义泄露",
      "注意力机制",
      "信息流控制",
      "图像多样性",
      "用户控制"
    ]
  }
}