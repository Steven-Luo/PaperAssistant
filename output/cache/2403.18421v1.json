{
  "id": "2403.18421v1",
  "title": "BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text",
  "pdf_url": "http://arxiv.org/pdf/2403.18421v1",
  "raw_tldr": "动机：当前大型生物医学自然语言处理模型虽然性能出色，但参数众多、运行成本高、数据来源不明确，因此研究者希望探索更小、更有针对性的模型是否能达到与大型模型相媲美的效果，同时提供透明性、隐私保护、经济和环保的基础。\n方法：研究者构建并发布了一个名为BioMedLM的模型，这是一个27亿参数的GPT风格自回归模型，专门针对PubMed的摘要和全文文章进行训练。通过微调，BioMedLM能够在多项选择题的生物医学问答任务中产生强大的结果。\n结果：BioMedLM在MedMCQA（开发版）上的得分达到57.3%，在MMLU医学遗传学考试上达到69.0%，与更大的模型有竞争力。此外，BioMedLM还可以被微调以产生对医疗主题患者问题的有用答案。模型已在Hugging Face Hub上提供。",
  "tldr": {
    "动机：当前大型生物医学自然语言处理模型虽然性能出色，但参数众多、运行成本高、数据来源不明确，因此研究者希望探索更小、更有针对性的模型是否能达到与大型模型相媲美的效果，同时提供透明性、隐私保护、经济和环保的基础。": "",
    "方法：研究者构建并发布了一个名为BioMedLM的模型，这是一个27亿参数的GPT风格自回归模型，专门针对PubMed的摘要和全文文章进行训练。通过微调，BioMedLM能够在多项选择题的生物医学问答任务中产生强大的结果。": "",
    "结果：BioMedLM在MedMCQA（开发版）上的得分达到57.3%，在MMLU医学遗传学考试上达到69.0%，与更大的模型有竞争力。此外，BioMedLM还可以被微调以产生对医疗主题患者问题的有用答案。模型已在Hugging Face Hub上提供。": "",
    "动机": "",
    "方法": "",
    "结果": ""
  },
  "summary_cn": "像GPT-4和Med-PaLM 2这样的模型在多种生物医学自然语言处理（NLP）任务上展示了令人印象深刻的性能。然而，这些模型拥有数千亿个参数，运行起来计算成本高昂，需要用户通过互联网发送他们的输入数据，并且它们是在未知数据源上进行训练的。那么，更小、更有针对性的模型能否与之竞争呢？为了解决这个问题，我们构建并发布了BioMedLM，这是一个拥有27亿参数的GPT风格的自回归模型，专门在PubMed摘要和全文文章上进行训练。当对BioMedLM进行微调后，它可以产生与更大的模型相媲美的强大多项选择生物医学问题回答结果，例如在MedMCQA（开发版）上达到57.3%的得分，在MMLU医学遗传学考试上达到69.0%的得分。BioMedLM还可以被微调以产生对医学主题的患者问题有用的答案。这表明，更小的模型有可能作为特定NLP应用的透明、保护隐私、经济且环保的基础，例如在生物医学领域。该模型可在Hugging Face Hub上获取：https://huggingface.co/stanford-crfm/BioMedLM。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"NLP\",\n  \"标签\": [\"生物医学\", \"自然语言处理\", \"模型训练\", \"模型压缩\", \"多任务学习\", \"数据隐私\", \"环境友好\", \"Hugging Face Hub\"]\n}\n```",
  "tag_info": {
    "主要领域": "NLP",
    "标签": [
      "生物医学",
      "自然语言处理",
      "模型训练",
      "模型压缩",
      "多任务学习",
      "数据隐私",
      "环境友好",
      "Hugging Face Hub"
    ]
  }
}