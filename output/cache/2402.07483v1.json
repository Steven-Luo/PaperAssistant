{
  "id": "2402.07483v1",
  "title": "T-RAG: Lessons from the LLM Trenches",
  "pdf_url": "http://arxiv.org/pdf/2402.07483v1",
  "raw_tldr": "动机\t大型语言模型（LLM）展现出卓越的语言能力，激发了将其集成到各个领域应用中的尝试。特别是在私有企业文件的问答应用中，数据安全、有限的计算资源和对准确响应查询的强烈需求成为主要考虑因素。\n方法\t文章分享了构建和部署一个用于私有组织文件问答的LLM应用的经验。该应用结合了检索增强生成（RAG）框架和一个微调的开源LLM，同时引入了一种称为Tree-RAG（T-RAG）的系统，使用树状结构来表示组织内的实体层次，以增强对用户查询的上下文响应。\n结果\t评估显示，这种结合RAG和微调LLM的方法比简单的RAG或微调实现表现更好。最后，基于构建实际使用的LLM应用的经验，分享了一些学到的教训。",
  "tldr": {
    "动机": "大型语言模型（LLM）展现出卓越的语言能力，激发了将其集成到各个领域应用中的尝试。特别是在私有企业文件的问答应用中，数据安全、有限的计算资源和对准确响应查询的强烈需求成为主要考虑因素。",
    "方法": "文章分享了构建和部署一个用于私有组织文件问答的LLM应用的经验。该应用结合了检索增强生成（RAG）框架和一个微调的开源LLM，同时引入了一种称为Tree-RAG（T-RAG）的系统，使用树状结构来表示组织内的实体层次，以增强对用户查询的上下文响应。",
    "结果": "评估显示，这种结合RAG和微调LLM的方法比简单的RAG或微调实现表现更好。最后，基于构建实际使用的LLM应用的经验，分享了一些学到的教训。"
  },
  "summary_cn": "大型语言模型（LLM）已经展现出了卓越的语言处理能力，这促使人们尝试将它们集成到各个领域的应用中。一个重要的应用领域是对私有企业文档进行问答，其中主要考虑因素是数据安全，这需要可以在本地部署的应用程序、有限的计算资源以及对查询做出正确响应的健壮应用程序。检索增强生成（RAG）已成为构建基于LLM应用的最突出框架。虽然构建RAG相对直接，但要使其成为健壮且可靠的应用需要广泛的定制和相对深入的应用领域知识。我们分享了构建和部署一个用于私有组织文档问答的LLM应用的经验。我们的应用结合了使用RAG和一个微调的开源LLM。此外，我们的系统，我们称之为树形RAG（T-RAG），使用树结构来表示组织内的实体层次。这用于生成文本描述，以在回应用户关于组织层次内实体的查询时增强上下文。我们的评估显示，这种组合的表现优于简单的RAG或微调实现。最后，我们基于构建实际使用的LLM应用的经验分享了一些学到的教训。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"NLP\",\n  \"标签\": [\n    \"Large Language Models\",\n    \"Question Answering\",\n    \"Data Security\",\n    \"Retrieval-Augmented Generation\",\n    \"On-prem Deployment\",\n    \"Entity Hierarchies\",\n    \"Finetuning\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "NLP",
    "标签": [
      "Large Language Models",
      "Question Answering",
      "Data Security",
      "Retrieval-Augmented Generation",
      "On-prem Deployment",
      "Entity Hierarchies",
      "Finetuning"
    ]
  }
}