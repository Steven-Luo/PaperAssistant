{
  "id": "2403.17005v1",
  "title": "TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models",
  "pdf_url": "http://arxiv.org/pdf/2403.17005v1",
  "raw_tldr": "动机：本文旨在解决在使用扩散模型进行图像到视频生成时的挑战，即如何在保持给定图像的真实对齐的同时，实现相邻帧之间的时间连贯性。\n\n方法：提出了一种名为TRIP的新型图像到视频扩散范式，该范式通过从静态图像中派生图像噪声先验，并结合噪声视频潜在代码来触发帧间关系推理，并通过时间残差学习简化连贯的时间建模。具体技术包括通过基于静态图像和噪声视频潜在代码的单步反向扩散过程首先获得图像噪声先验，然后执行类似残差的双路径方案来预测噪声：一个是直接将图像噪声先验作为每帧的参考噪声以增强第一帧与后续帧之间的对齐；另一个是通过3D-UNet在噪声视频和静态图像潜在代码上进行操作，以启用帧间关系推理，从而简化每帧残差噪声的学习。此外，每帧的参考噪声和残差噪声通过注意力机制动态合并，以生成最终视频。\n\n结果：在WebVid-10M、DTDB和MSR-VTT数据集上的广泛实验表明，我们的TRIP模型在图像到视频生成方面非常有效。",
  "tldr": {
    "动机：本文旨在解决在使用扩散模型进行图像到视频生成时的挑战，即如何在保持给定图像的真实对齐的同时，实现相邻帧之间的时间连贯性。": "",
    "方法：提出了一种名为TRIP的新型图像到视频扩散范式，该范式通过从静态图像中派生图像噪声先验，并结合噪声视频潜在代码来触发帧间关系推理，并通过时间残差学习简化连贯的时间建模。具体技术包括通过基于静态图像和噪声视频潜在代码的单步反向扩散过程首先获得图像噪声先验，然后执行类似残差的双路径方案来预测噪声：一个是直接将图像噪声先验作为每帧的参考噪声以增强第一帧与后续帧之间的对齐；另一个是通过3D-UNet在噪声视频和静态图像潜在代码上进行操作，以启用帧间关系推理，从而简化每帧残差噪声的学习。此外，每帧的参考噪声和残差噪声通过注意力机制动态合并，以生成最终视频。": "",
    "结果：在WebVid-10M、DTDB和MSR-VTT数据集上的广泛实验表明，我们的TRIP模型在图像到视频生成方面非常有效。": "",
    "动机": "",
    "方法": "",
    "结果": ""
  },
  "summary_cn": "近期在文本到视频生成方面的进展已经展示了强大扩散模型的实用性。然而，当塑造扩散模型以动画化静态图像（即图像到视频生成）时，问题并不简单。难点在于后续动画帧的扩散过程不仅应该保留与给定图像的忠实对齐，还应该追求相邻帧之间的时间连贯性。为了缓解这一问题，我们提出了TRIP，这是一种新的图像到视频扩散范式，它基于从静态图像派生的图像噪声先验，通过联合触发帧间关系推理和通过时间残差学习简化连贯的时间建模。技术上，首先通过基于静态图像和噪声视频潜在代码的单步反向扩散过程获得图像噪声先验。接下来，TRIP执行一个类似残差的双通道方案来预测噪声：1）一个直接将图像噪声先验作为每个帧的参考噪声的快捷路径，以增强第一帧与后续帧之间的对齐；2）一个残差路径，它使用3D-UNet在噪声视频和静态图像潜在代码上进行操作，以实现帧间关系推理，从而简化每帧残差噪声的学习。此外，每个帧的参考噪声和残差噪声通过注意力机制动态合并，用于最终视频生成。在WebVid-10M、DTDB和MSR-VTT数据集上的广泛实验证明了我们的TRIP在图像到视频生成方面的有效性。请访问我们的项目页面 https://trip-i2v.github.io/TRIP/ 了解更多信息。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"CV\",\n  \"标签\": [\"text-to-video generation\", \"image-to-video generation\", \"diffusion models\", \"temporal coherence\", \"image noise prior\", \"temporal residual learning\", \"3D-UNet\", \"attention mechanism\", \"video generation\", \"WebVid-10M\", \"DTDB\", \"MSR-VTT\"]\n}\n```",
  "tag_info": {
    "主要领域": "CV",
    "标签": [
      "text-to-video generation",
      "image-to-video generation",
      "diffusion models",
      "temporal coherence",
      "image noise prior",
      "temporal residual learning",
      "3D-UNet",
      "attention mechanism",
      "video generation",
      "WebVid-10M",
      "DTDB",
      "MSR-VTT"
    ]
  }
}