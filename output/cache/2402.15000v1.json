{
  "id": "2402.15000v1",
  "raw_tldr": "#动机：近期方法表明，当大型语言模型（LLMs）被鼓励首先解决主任务的子任务时，它们在解决推理任务方面的表现更佳。本文旨在通过将推理任务分解为问题分解阶段和问题解决阶段的策略，来验证该策略是否能够胜过单一阶段的解决方案。\n\n#方法：提出了一种方法，将推理任务分解为问题分解和问题解决两个阶段，并提出了将这两种能力蒸馏（distill）到较小模型中的方法，并评估了它们对推理结果和推理成本的影响。\n\n#结果：发现可以将问题分解阶段蒸馏下来，并同时在任务、数据集和模型之间实现良好的泛化。但是，蒸馏问题解决能力较难，且所得到的蒸馏模型在泛化方面存在挑战。这些结果表明，通过使用较小的、蒸馏过的问题分解模型与问题解决LLMs结合，我们可以实现具有成本效益的推理和本地适应。",
  "tldr": {
    "": "结果：发现可以将问题分解阶段蒸馏下来，并同时在任务、数据集和模型之间实现良好的泛化。但是，蒸馏问题解决能力较难，且所得到的蒸馏模型在泛化方面存在挑战。这些结果表明，通过使用较小的、蒸馏过的问题分解模型与问题解决LLMs结合，我们可以实现具有成本效益的推理和本地适应。",
    "动机": "",
    "方法": "",
    "结果": ""
  },
  "summary_cn": "最近的方法已经证明，当大型语言模型（LLMs）被鼓励首先解决主任务的子任务时，它们能够更好地解决推理任务。在本文中，我们设计了一种类似的策略，将推理任务分解为问题分解阶段和问题解决阶段，并展示了这种策略能够胜过单一阶段的解决方案。进一步地，我们假设与问题解决相比，分解应该更容易被提炼到一个较小的模型中，因为后者需要大量的领域知识，而前者只需要学习通用的问题解决策略。我们提出了提炼这两种能力的方法，并评估它们对推理结果和推理成本的影响。我们发现，我们可以提炼问题分解阶段，并同时在任务、数据集和模型之间实现良好的泛化。然而，提炼问题解决能力而不损失性能更加困难，结果表明提炼后的模型在泛化方面存在挑战。这些结果表明，通过使用较小的、提炼后的问题分解模型与问题解决LLMs相结合，我们可以实现具有成本效益的推理和本地适应。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"Machine Learning\",\n  \"标签\": [\n    \"Large Language Models\",\n    \"Reasoning Tasks\",\n    \"Problem Decomposition\",\n    \"Model Distillation\",\n    \"Inference Cost\",\n    \"Generalization\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "Machine Learning",
    "标签": [
      "Large Language Models",
      "Reasoning Tasks",
      "Problem Decomposition",
      "Model Distillation",
      "Inference Cost",
      "Generalization"
    ]
  }
}