{
  "id": "2403.05135v1",
  "title": "ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment",
  "pdf_url": "http://arxiv.org/pdf/2403.05135v1",
  "raw_tldr": "动机\t现有的文本到图像生成的扩散模型大多使用CLIP作为文本编码器，这限制了它们理解包含多个对象、详细属性、复杂关系、长文本对齐等密集提示的能力。\n方法\t本文介绍了一种高效的大型语言模型适配器（ELLA），通过不需要对U-Net或LLM进行训练的方式，将强大的大型语言模型（LLM）与文本到图像的扩散模型结合，使用了一种新颖的模块——时间步感知的语义连接器（TSC），动态地从LLM中提取时间步依赖的条件，以适应去噪过程中不同阶段的语义特征。\n结果\t通过引入一个包含1K密集提示的挑战性基准测试（DPG-Bench）并进行广泛实验，结果显示ELLA在密集提示跟随方面相比于现有最先进方法表现出了优越性，特别是在涉及多个对象组成、不同属性和关系方面。",
  "tldr": {
    "动机": "现有的文本到图像生成的扩散模型大多使用CLIP作为文本编码器，这限制了它们理解包含多个对象、详细属性、复杂关系、长文本对齐等密集提示的能力。",
    "方法": "本文介绍了一种高效的大型语言模型适配器（ELLA），通过不需要对U-Net或LLM进行训练的方式，将强大的大型语言模型（LLM）与文本到图像的扩散模型结合，使用了一种新颖的模块——时间步感知的语义连接器（TSC），动态地从LLM中提取时间步依赖的条件，以适应去噪过程中不同阶段的语义特征。",
    "结果": "通过引入一个包含1K密集提示的挑战性基准测试（DPG-Bench）并进行广泛实验，结果显示ELLA在密集提示跟随方面相比于现有最先进方法表现出了优越性，特别是在涉及多个对象组成、不同属性和关系方面。"
  },
  "summary_cn": "扩散模型在文本到图像生成领域展现出了卓越的性能。然而，大多数广泛使用的模型仍然采用CLIP作为它们的文本编码器，这限制了它们理解包含多个对象、详细属性、复杂关系、长文本对齐等密集提示的能力。在本文中，我们介绍了一个高效的大型语言模型适配器，称为ELLA，它为文本到图像扩散模型配备了强大的大型语言模型（LLM），以增强文本对齐，而无需对U-Net或LLM进行训练。为了无缝连接两个预训练模型，我们研究了一系列语义对齐连接器设计，并提出了一个新颖的模块，即时间步感知的语义连接器（TSC），它能够动态地从LLM中提取依赖于时间步的条件。我们的方法在去噪过程的不同阶段调整语义特征，帮助扩散模型在采样时间步中解释长且复杂的提示。此外，ELLA可以轻松地与社区模型和工具集成，以提高它们的提示跟随能力。为了评估文本到图像模型在密集提示跟随方面的性能，我们引入了密集提示图基准（DPG-Bench），这是一个由1K个密集提示组成的具有挑战性的基准。广泛的实验表明，与最先进的方法相比，ELLA在密集提示跟随方面表现出了优越性，特别是在涉及多个对象组成、涉及多样属性和关系的情况下。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"文本到图像生成\",\n    \"扩散模型\",\n    \"大型语言模型\",\n    \"语义对齐\",\n    \"密集提示\",\n    \"性能评估\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "文本到图像生成",
      "扩散模型",
      "大型语言模型",
      "语义对齐",
      "密集提示",
      "性能评估"
    ]
  }
}