{
  "id": "2402.10200v1",
  "title": "Chain-of-Thought Reasoning Without Prompting",
  "pdf_url": "http://arxiv.org/pdf/2402.10200v1",
  "raw_tldr": "动机\t提升大型语言模型(LLMs)的推理能力，先前研究主要集中在特定的提示技术，如少数样本或零样本的思维链提示，这些方法虽有效，但常涉及手动密集的提示工程。本研究提出一个新颖的问题：不使用提示，LLMs能否有效推理？\n方法\t通过简单改变解码过程，从预训练的LLMs中引出思维链推理路径，研究了top-k替代令牌，发现这些序列中经常固有地包含思维链路径。这种方法不仅绕过了提示的混淆因素，还允许我们评估LLMs的内在推理能力。\n结果\t发现解码路径中思维链的存在与模型解码答案的高置信度相关联，这个置信度指标有效区分了思维链与非思维链路径。在各种推理基准上的广泛实证研究表明，所提出的思维链解码大大优于标准的贪婪解码。",
  "tldr": {
    "动机": "提升大型语言模型(LLMs)的推理能力，先前研究主要集中在特定的提示技术，如少数样本或零样本的思维链提示，这些方法虽有效，但常涉及手动密集的提示工程。本研究提出一个新颖的问题：不使用提示，LLMs能否有效推理？",
    "方法": "通过简单改变解码过程，从预训练的LLMs中引出思维链推理路径，研究了top-k替代令牌，发现这些序列中经常固有地包含思维链路径。这种方法不仅绕过了提示的混淆因素，还允许我们评估LLMs的内在推理能力。",
    "结果": "发现解码路径中思维链的存在与模型解码答案的高置信度相关联，这个置信度指标有效区分了思维链与非思维链路径。在各种推理基准上的广泛实证研究表明，所提出的思维链解码大大优于标准的贪婪解码。"
  },
  "summary_cn": "在增强大型语言模型（LLMs）的推理能力方面，先前的研究主要集中在特定的提示技术上，如少量样本或零样本的思维链（CoT）提示。这些方法虽然有效，但往往涉及到手工密集型的提示工程。我们的研究采取了一种新颖的方法，提出了这样一个问题：大型语言模型能在没有提示的情况下有效地进行推理吗？我们的发现揭示了一个有趣的现象，即通过简单地改变\\textit{解码}过程，可以从预训练的LLMs中引出CoT推理路径。我们研究了前$k$个备选词汇，而不是传统的贪婪解码，发现CoT路径经常固有地存在于这些序列中。这种方法不仅绕过了提示的混淆因素，而且还允许我们评估LLMs的\\textit{内在}推理能力。此外，我们观察到，在解码路径中出现CoT与模型解码答案的更高置信度相关联。这个置信度指标有效地区分了CoT路径和非CoT路径。在各种推理基准测试上的广泛实证研究表明，所提出的CoT解码大大优于标准的贪婪解码。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"NLP\",\n  \"标签\": [\n    \"large language models\",\n    \"reasoning capabilities\",\n    \"chain-of-thought prompting\",\n    \"decoding process\",\n    \"top-k alternative tokens\",\n    \"intrinsic reasoning abilities\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "NLP",
    "标签": [
      "large language models",
      "reasoning capabilities",
      "chain-of-thought prompting",
      "decoding process",
      "top-k alternative tokens",
      "intrinsic reasoning abilities"
    ]
  }
}