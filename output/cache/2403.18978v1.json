{
  "id": "2403.18978v1",
  "title": "TextCraftor: Your Text Encoder Can be Image Quality Controller",
  "pdf_url": "http://arxiv.org/pdf/2403.18978v1",
  "raw_tldr": "动机\t尽管基于扩散的文本到图像生成模型（例如稳定扩散）在内容生成领域取得了重大进展，但这些模型在与输入文本紧密对齐的图像合成方面仍存在挑战，需要多次尝试和精心设计的提示来获得满意的结果。\n方法\t本文提出了一种名为TextCraftor的文本编码器微调方法，而不是用其他大型语言模型替换稳定扩散中使用的CLIP文本编码器，以增强其性能。\n结果\t我们的实验结果显示，TextCraftor不仅在定量基准测试和人类评估中取得了显著改进，而且通过不同奖励微调的文本编码器的插值还能实现可控图像生成，此外，我们还证明了TextCraftor与UNet微调是正交的，可以结合使用以进一步提高生成质量。",
  "tldr": {
    "动机": "尽管基于扩散的文本到图像生成模型（例如稳定扩散）在内容生成领域取得了重大进展，但这些模型在与输入文本紧密对齐的图像合成方面仍存在挑战，需要多次尝试和精心设计的提示来获得满意的结果。",
    "方法": "本文提出了一种名为TextCraftor的文本编码器微调方法，而不是用其他大型语言模型替换稳定扩散中使用的CLIP文本编码器，以增强其性能。",
    "结果": "我们的实验结果显示，TextCraftor不仅在定量基准测试和人类评估中取得了显著改进，而且通过不同奖励微调的文本编码器的插值还能实现可控图像生成，此外，我们还证明了TextCraftor与UNet微调是正交的，可以结合使用以进一步提高生成质量。"
  },
  "summary_cn": "基于扩散的文本到图像生成模型，例如Stable Diffusion，已经彻底改变了内容生成领域，使得图像编辑和视频合成等领域取得了重大进展。尽管这些模型功能强大，但它们并非没有局限性。要合成与输入文本高度一致的图像仍然具有挑战性，需要多次运行并使用精心设计的提示才能获得令人满意的结果。为了克服这些局限性，许多研究致力于利用各种技术对预训练的扩散模型，即UNet，进行微调。然而，在这些努力中，文本到图像扩散模型训练的一个关键问题尚未得到广泛探索：是否有可能并可行地对文本编码器进行微调以提高文本到图像扩散模型的性能？我们的发现表明，我们可以通过我们提出的微调方法TextCraftor来增强Stable Diffusion中使用的CLIP文本编码器，而不是用其他大型语言模型来替换它，这在定量基准测试和人类评估中都带来了显著的改进。有趣的是，我们的技术还通过不同文本编码器的插值微调实现了可控的图像生成，这些编码器针对各种奖励进行了优化。我们还展示了TextCraftor与UNet微调是正交的，可以结合使用以进一步提高生成质量。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\"文本到图像生成\", \"生成模型\", \"微调\", \"Stable Diffusion\", \"UNet\", \"CLIP\", \"TextCraftor\", \"定量评估\", \"人类评估\", \"可控图像生成\"]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "文本到图像生成",
      "生成模型",
      "微调",
      "Stable Diffusion",
      "UNet",
      "CLIP",
      "TextCraftor",
      "定量评估",
      "人类评估",
      "可控图像生成"
    ]
  }
}