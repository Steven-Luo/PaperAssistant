{
  "id": "2402.17753v1",
  "raw_tldr": "动机\t现有的长期开放域对话研究主要集中在评估模型在不超过五个聊天会话范围内的响应。尽管在长上下文大型语言模型（LLMs）和检索增强生成（RAG）技术方面取得了进步，但它们在非常长期对话中的有效性仍未探索。\n方法\t引入了一个机器-人类管道，通过利用基于LLM的代理架构并将对话基于人物角色和时间事件图来生成高质量的非常长期对话。此外，为每个代理配备了共享和对图像做出反应的能力。通过人类注释者验证和编辑生成的对话，以确保长期一致性和与事件图的紧密结合。使用此管道，收集了LoCoMo数据集，包含平均每个对话300轮、9K令牌，最多35个会话的非常长期对话。\n结果\tLLMs在理解冗长对话和理解对话中的长期时间和因果动态方面面临挑战。采用长上下文LLMs或RAG等策略可以提供改进，但这些模型的性能仍然大大落后于人类表现。",
  "tldr": {
    "动机": "现有的长期开放域对话研究主要集中在评估模型在不超过五个聊天会话范围内的响应。尽管在长上下文大型语言模型（LLMs）和检索增强生成（RAG）技术方面取得了进步，但它们在非常长期对话中的有效性仍未探索。",
    "方法": "引入了一个机器-人类管道，通过利用基于LLM的代理架构并将对话基于人物角色和时间事件图来生成高质量的非常长期对话。此外，为每个代理配备了共享和对图像做出反应的能力。通过人类注释者验证和编辑生成的对话，以确保长期一致性和与事件图的紧密结合。使用此管道，收集了LoCoMo数据集，包含平均每个对话300轮、9K令牌，最多35个会话的非常长期对话。",
    "结果": "LLMs在理解冗长对话和理解对话中的长期时间和因果动态方面面临挑战。采用长上下文LLMs或RAG等策略可以提供改进，但这些模型的性能仍然大大落后于人类表现。"
  },
  "summary_cn": "现有的关于长期开放领域对话的研究主要集中在评估模型在不超过五个聊天会话范围内的上下文响应。尽管在长上下文大型语言模型（LLMs）和检索增强生成（RAG）技术方面取得了进步，但它们在非常长期对话中的有效性仍未被探索。为了解决这一研究空白，我们引入了一个机器-人类管道，通过利用基于LLM的代理架构，并将它们的对话基于人物角色和时间事件图来生成高质量的非常长期对话。此外，我们还为每个代理配备了共享和反应图像的能力。生成的对话由人类注释者进行验证和编辑，以确保长期一致性和与事件图的关联。通过这一管道，我们收集了LoCoMo，一个非常长期对话的数据集，每个对话平均包含300个回合和9K个令牌，最多达到35个会话。基于LoCoMo，我们提出了一个全面的评估基准，以衡量模型中的长期记忆，包括问答、事件总结和多模态对话生成任务。我们的实验结果表明，LLMs在理解冗长对话和理解对话中的长期时间和因果动态方面面临挑战。采用长上下文LLMs或RAG等策略可以提供改进，但这些模型的性能仍然大大落后于人类表现。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"NLP\",\n  \"标签\": [\n    \"长期对话\",\n    \"大型语言模型\",\n    \"检索增强生成\",\n    \"多模态\",\n    \"对话生成\",\n    \"数据集\",\n    \"长期记忆评估\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "NLP",
    "标签": [
      "长期对话",
      "大型语言模型",
      "检索增强生成",
      "多模态",
      "对话生成",
      "数据集",
      "长期记忆评估"
    ]
  }
}