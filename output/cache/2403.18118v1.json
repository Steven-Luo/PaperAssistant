{
  "id": "2403.18118v1",
  "title": "EgoLifter: Open-world 3D Segmentation for Egocentric Perception",
  "pdf_url": "http://arxiv.org/pdf/2403.18118v1",
  "raw_tldr": "动机\t本论文提出了EgoLifter系统，旨在解决如何自动将来自以自我为中心的传感器捕获的场景分解为独立的3D对象的完整分解问题，特别是针对自然（非扫描）运动中包含数百个对象的场景。\n方法\t系统采用3D高斯作为3D场景和对象的基本表示，并使用来自Segment Anything Model（SAM）的分割掩码作为弱监督，以学习灵活且可提示的对象实例定义，这些定义不受任何特定对象分类的限制。为了应对以自我为中心的视频中动态对象的挑战，设计了一个瞬态预测模块，该模块学习过滤掉3D重建中的动态对象。\n结果\t实现了一个完全自动化的流程，能够将3D对象实例重建为3D高斯的集合，这些高斯共同构成了整个场景。通过在Aria Digital Twin数据集上创建的新基准，定量展示了其在自然以自我为中心输入的开放世界3D分割方面的最新性能。在各种以自我为中心的活动数据集上运行EgoLifter，显示了该方法在大规模3D以自我为中心的感知方面的潜力。",
  "tldr": {
    "动机": "本论文提出了EgoLifter系统，旨在解决如何自动将来自以自我为中心的传感器捕获的场景分解为独立的3D对象的完整分解问题，特别是针对自然（非扫描）运动中包含数百个对象的场景。",
    "方法": "系统采用3D高斯作为3D场景和对象的基本表示，并使用来自Segment Anything Model（SAM）的分割掩码作为弱监督，以学习灵活且可提示的对象实例定义，这些定义不受任何特定对象分类的限制。为了应对以自我为中心的视频中动态对象的挑战，设计了一个瞬态预测模块，该模块学习过滤掉3D重建中的动态对象。",
    "结果": "实现了一个完全自动化的流程，能够将3D对象实例重建为3D高斯的集合，这些高斯共同构成了整个场景。通过在Aria Digital Twin数据集上创建的新基准，定量展示了其在自然以自我为中心输入的开放世界3D分割方面的最新性能。在各种以自我为中心的活动数据集上运行EgoLifter，显示了该方法在大规模3D以自我为中心的感知方面的潜力。"
  },
  "summary_cn": "在这篇论文中，我们介绍了EgoLifter，这是一个新颖的系统，能够自动将从以自我为中心的传感器捕获的场景分割成完整的个体3D对象分解。该系统专门为以自我为中心的数据设计，这些数据中的场景包含了数百个从自然（非扫描）运动中捕获的对象。EgoLifter采用3D高斯作为3D场景和对象的基本表示，并使用来自“任何对象模型”（SAM）的分割掩模作为弱监督，以学习灵活的、可提示的对象实例定义，这些定义不受任何特定对象分类体系的限制。为了处理以自我为中心的视频中动态对象的挑战，我们设计了一个瞬态预测模块，该模块学习如何过滤掉3D重建中的动态对象。其结果是一个完全自动化的流程，能够将3D对象实例重建为3D高斯的集合，共同组成整个场景。我们创建了一个新的基准测试，使用Aria数字孪生数据集，定量展示了其在从自然以自我为中心的输入中进行开放世界3D分割方面的最新技术水平。我们在各种以自我为中心的活动数据集上运行EgoLifter，展示了该方法在大规模3D以自我为中心的感知方面的潜力。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"CV\",\n  \"标签\": [\"3D重建\", \"场景分割\", \"物体识别\", \"弱监督学习\", \"动态对象处理\", \"基准测试\", \"自然运动捕捉\", \"第一人称视角\"]\n}\n```",
  "tag_info": {
    "主要领域": "CV",
    "标签": [
      "3D重建",
      "场景分割",
      "物体识别",
      "弱监督学习",
      "动态对象处理",
      "基准测试",
      "自然运动捕捉",
      "第一人称视角"
    ]
  }
}