{
  "id": "2403.14773v1",
  "title": "StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation from Text",
  "pdf_url": "http://arxiv.org/pdf/2403.14773v1",
  "raw_tldr": "动机\t文本到视频的扩散模型能够生成遵循文本指令的高质量视频，便于创造多样和个性化内容。然而，现有方法主要关注高质量短视频（通常为16或24帧）的生成，当天真地扩展到长视频合成时会出现硬切割。为了克服这些限制，我们引入了StreamingT2V。\n方法\tStreamingT2V是一种自回归方法，用于生成具有平滑过渡的80、240、600、1200或更多帧的长视频。关键组件包括：(i) 一个名为条件注意力模块（CAM）的短期记忆块，它通过注意力机制使当前生成依赖于从前一个块提取的特征，实现一致的块过渡；(ii) 一个名为外观保持模块的长期记忆块，它从第一个视频块提取高级场景和对象特征，防止模型忘记初始场景；以及(iii) 一个随机混合方法，该方法能够在不产生块之间不一致的情况下，自回归地应用视频增强器，以无限长的视频。\n结果\t实验表明，StreamingT2V能够生成高运动量的视频。相比之下，所有竞争的图像到视频方法在以自回归方式天真地应用时，都容易导致视频停滞。因此，我们提出的StreamingT2V是一个高质量、无缝的文本到长视频生成器，它在一致性和运动方面胜过竞争对手。我们的代码将在https://github.com/Picsart-AI-Research/StreamingT2V上提供。",
  "tldr": {
    "动机": "文本到视频的扩散模型能够生成遵循文本指令的高质量视频，便于创造多样和个性化内容。然而，现有方法主要关注高质量短视频（通常为16或24帧）的生成，当天真地扩展到长视频合成时会出现硬切割。为了克服这些限制，我们引入了StreamingT2V。",
    "方法": "StreamingT2V是一种自回归方法，用于生成具有平滑过渡的80、240、600、1200或更多帧的长视频。关键组件包括：(i) 一个名为条件注意力模块（CAM）的短期记忆块，它通过注意力机制使当前生成依赖于从前一个块提取的特征，实现一致的块过渡；(ii) 一个名为外观保持模块的长期记忆块，它从第一个视频块提取高级场景和对象特征，防止模型忘记初始场景；以及(iii) 一个随机混合方法，该方法能够在不产生块之间不一致的情况下，自回归地应用视频增强器，以无限长的视频。",
    "结果": "实验表明，StreamingT2V能够生成高运动量的视频。相比之下，所有竞争的图像到视频方法在以自回归方式天真地应用时，都容易导致视频停滞。因此，我们提出的StreamingT2V是一个高质量、无缝的文本到长视频生成器，它在一致性和运动方面胜过竞争对手。我们的代码将在https://github.com/Picsart-AI-Research/StreamingT2V上提供。"
  },
  "summary_cn": "文本到视频的扩散模型使得生成遵循文本指令的高质量视频变得简单，从而容易创造多样化和个性化的内容。然而，现有的方法大多集中在生成高质量短视频（通常是16或24帧），当天真地扩展到长视频合成的情况时，最终会出现硬切断。为了克服这些限制，我们引入了StreamingT2V，一种用于生成80、240、600、1200或更多帧的长视频的自回归方法，具有平滑过渡。关键组件包括：(i) 一个称为条件注意模块（CAM）的短期记忆块，它通过注意力机制将当前生成条件化于从前一块视频中提取的特征上，从而实现一致的块过渡；(ii) 一个称为外观保持模块的长期记忆块，它从第一个视频块中提取高级场景和对象特征，以防止模型忘记初始场景；以及(iii) 一种随机混合方法，它使得可以自回归地应用视频增强器于无限长的视频，而不会在块之间出现不一致。实验表明，StreamingT2V产生高运动量。相比之下，所有竞争的图像到视频方法在以自回归方式天真地应用时都容易导致视频停滞。因此，我们提出StreamingT2V是一个高质量、无缝的文本到长视频生成器，它在一致性和运动方面超越了竞争对手。我们的代码将在以下网址提供：https://github.com/Picsart-AI-Research/StreamingT2V",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\"text-to-video\", \"video generation\", \"autoregressive model\", \"conditional attention\", \"appearance preservation\", \"randomized blending\", \"high motion\"]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "text-to-video",
      "video generation",
      "autoregressive model",
      "conditional attention",
      "appearance preservation",
      "randomized blending",
      "high motion"
    ]
  }
}