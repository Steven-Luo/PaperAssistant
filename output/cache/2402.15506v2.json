{
  "id": "2402.15506v2",
  "raw_tldr": "动机\t自动化代理由大型语言模型（LLMs）驱动，引起了显著的研究关注。然而，充分利用LLMs为基于代理的任务提供动力存在固有挑战，这是由于不同数据源的异质性质，特别是包含多轮轨迹的数据。\n方法\t本文介绍了\\textbf{AgentOhana}作为一个全面的解决方案来应对这些挑战。\\textit{AgentOhana}聚合来自不同环境的代理轨迹，涵盖广泛的场景。它细致地将这些轨迹标准化和统一成一致的格式，简化了为代理训练优化的通用数据加载器的创建。利用数据统一，我们的训练管道在不同数据源之间保持平衡，并在数据集划分和模型训练期间保持设备间的独立随机性。\n结果\t此外，我们还提出了\\textbf{xLAM-v0.1}，一个为AI代理量身定制的大型行动模型，该模型在各种基准测试中展示了卓越的性能。",
  "tldr": {
    "动机": "自动化代理由大型语言模型（LLMs）驱动，引起了显著的研究关注。然而，充分利用LLMs为基于代理的任务提供动力存在固有挑战，这是由于不同数据源的异质性质，特别是包含多轮轨迹的数据。",
    "方法": "本文介绍了\\textbf{AgentOhana}作为一个全面的解决方案来应对这些挑战。\\textit{AgentOhana}聚合来自不同环境的代理轨迹，涵盖广泛的场景。它细致地将这些轨迹标准化和统一成一致的格式，简化了为代理训练优化的通用数据加载器的创建。利用数据统一，我们的训练管道在不同数据源之间保持平衡，并在数据集划分和模型训练期间保持设备间的独立随机性。",
    "结果": "此外，我们还提出了\\textbf{xLAM-v0.1}，一个为AI代理量身定制的大型行动模型，该模型在各种基准测试中展示了卓越的性能。"
  },
  "summary_cn": "由大型语言模型（LLMs）驱动的自主代理引起了显著的研究关注。然而，充分利用LLMs的潜力来执行基于代理的任务面临着固有的挑战，这是由于不同数据源的异质性质，特别是包含多轮交互轨迹的数据源。在本文中，我们介绍了\\textbf{AgentOhana}作为解决这些挑战的综合方案。\\textit{AgentOhana}聚合了来自不同环境的代理轨迹，涵盖了广泛的场景。它细致地将这些轨迹标准化并统一成一致的格式，简化了为代理训练优化的通用数据加载器的创建。利用数据统一，我们的训练流程在不同数据源之间保持平衡，并在数据集划分和模型训练期间保持设备间的独立随机性。此外，我们还介绍了\\textbf{xLAM-v0.1}，这是一个为AI代理量身定制的大型行动模型，它在各种基准测试中展示了卓越的性能。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"Machine Learning\",\n  \"标签\": [\n    \"large language models\",\n    \"autonomous agents\",\n    \"data unification\",\n    \"agent training\",\n    \"AI agents\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "Machine Learning",
    "标签": [
      "large language models",
      "autonomous agents",
      "data unification",
      "agent training",
      "AI agents"
    ]
  }
}