{
  "raw_tldr": "动机#由于巨大的计算成本，使用扩散模型生成高分辨率图像仍然是一个挑战，这导致了交互式应用中的禁止性延迟。\n\n方法#本文提出了DistriFusion，通过在多个GPU之间利用并行性来解决这一问题。方法通过将模型输入分割成多个补丁，并将每个补丁分配给一个GPU来实现。为了克服简单实现算法导致的补丁间交互断裂和保真度下降的问题，以及加入补丁间交互会导致巨大通信开销的问题，提出了一种基于相邻扩散步骤输入高相似性的位移补丁并行机制，通过重用前一时间步的预计算特征图为当前步骤提供上下文，支持异步通信，可以通过计算进行流水线处理。\n\n结果#通过广泛的实验表明，该方法可以应用于最近的Stable Diffusion XL而不降低质量，并且与单个NVIDIA A100相比，在八个NVIDIA A100上实现了高达6.1倍的加速。代码已公开可用。",
  "tldr": {
    "动机": "由于巨大的计算成本，使用扩散模型生成高分辨率图像仍然是一个挑战，这导致了交互式应用中的禁止性延迟。",
    "方法": "本文提出了DistriFusion，通过在多个GPU之间利用并行性来解决这一问题。方法通过将模型输入分割成多个补丁，并将每个补丁分配给一个GPU来实现。为了克服简单实现算法导致的补丁间交互断裂和保真度下降的问题，以及加入补丁间交互会导致巨大通信开销的问题，提出了一种基于相邻扩散步骤输入高相似性的位移补丁并行机制，通过重用前一时间步的预计算特征图为当前步骤提供上下文，支持异步通信，可以通过计算进行流水线处理。",
    "结果": "通过广泛的实验表明，该方法可以应用于最近的Stable Diffusion XL而不降低质量，并且与单个NVIDIA A100相比，在八个NVIDIA A100上实现了高达6.1倍的加速。代码已公开可用。"
  },
  "summary_cn": "扩散模型在合成高质量图像方面取得了巨大成功。然而，由于巨大的计算成本，使用扩散模型生成高分辨率图像仍然是一个挑战，这导致了交互式应用中禁止性的延迟。在本文中，我们提出了DistriFusion来通过利用多个GPU之间的并行性来解决这个问题。我们的方法将模型输入分割成多个补丁，并将每个补丁分配给一个GPU。然而，天真地实现这样的算法会破坏补丁之间的交互并且失去保真度，而纳入这种交互将会产生巨大的通信开销。为了克服这个两难问题，我们观察到相邻扩散步骤之间输入的高度相似性，并提出了位移补丁并行性，它通过重用前一个时间步骤的预计算特征图来为当前步骤提供上下文，从而利用扩散过程的顺序性质。因此，我们的方法支持异步通信，可以通过计算来流水线处理。广泛的实验表明，我们的方法可以应用于最近的Stable Diffusion XL而不降低质量，并且与一个NVIDIA A100相比，在八个NVIDIA A100上实现了高达6.1倍的加速。我们的代码在https://github.com/mit-han-lab/distrifuser上公开可用。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"CV\",\n  \"标签\": [\n    \"Diffusion models\",\n    \"High-resolution image synthesis\",\n    \"Parallel computing\",\n    \"GPU\",\n    \"Stable Diffusion XL\",\n    \"Speedup\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "CV",
    "标签": [
      "Diffusion models",
      "High-resolution image synthesis",
      "Parallel computing",
      "GPU",
      "Stable Diffusion XL",
      "Speedup"
    ]
  },
  "id": "2402.19481v1"
}