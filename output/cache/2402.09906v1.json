{
  "id": "2402.09906v1",
  "title": "Generative Representational Instruction Tuning",
  "pdf_url": "http://arxiv.org/pdf/2402.09906v1",
  "raw_tldr": "动机\t所有基于文本的语言问题都可以归结为生成问题或嵌入问题。当前模型只能在其中一个方面表现良好。\n方法\t我们引入了生成表征指令调整（GRIT），通过指令区分生成任务和嵌入任务，训练大型语言模型来同时处理这两种任务。\n结果\tGRITLM 7B在Massive Text Embedding Benchmark (MTEB)上设立了新的最高标准，并且在一系列生成任务上超越了所有同等大小的模型。通过进一步扩展，GritLM 8x7B超越了我们尝试的所有开放生成语言模型，同时仍然是最好的嵌入模型之一。GRIT实现了生成数据和嵌入数据训练的匹配，无需性能损失即可统一两者。通过GRIT的统一，对于长文档的检索增强生成（RAG）速度提高了60%以上，不再需要单独的检索和生成模型。",
  "tldr": {
    "动机": "所有基于文本的语言问题都可以归结为生成问题或嵌入问题。当前模型只能在其中一个方面表现良好。",
    "方法": "我们引入了生成表征指令调整（GRIT），通过指令区分生成任务和嵌入任务，训练大型语言模型来同时处理这两种任务。",
    "结果": "GRITLM 7B在Massive Text Embedding Benchmark (MTEB)上设立了新的最高标准，并且在一系列生成任务上超越了所有同等大小的模型。通过进一步扩展，GritLM 8x7B超越了我们尝试的所有开放生成语言模型，同时仍然是最好的嵌入模型之一。GRIT实现了生成数据和嵌入数据训练的匹配，无需性能损失即可统一两者。通过GRIT的统一，对于长文档的检索增强生成（RAG）速度提高了60%以上，不再需要单独的检索和生成模型。"
  },
  "summary_cn": "所有基于文本的语言问题都可以归结为生成问题或嵌入问题。当前的模型只能在其中一个方面表现良好。我们引入了生成式表征指令调整（GRIT），通过这种方式，一个大型语言模型被训练来同时处理生成任务和嵌入任务，并通过指令区分它们。与其他开放模型相比，我们的结果模型GritLM 7B在Massive Text Embedding Benchmark (MTEB)上设定了新的最高标准，并且在一系列生成任务上超越了所有同等大小的模型。通过进一步扩大规模，GritLM 8x7B超越了我们尝试的所有开放式生成语言模型，同时仍然是最佳嵌入模型之一。值得注意的是，我们发现GRIT与仅在生成数据或嵌入数据上进行训练相匹配，因此我们可以在不损失性能的情况下统一两者。除其他好处外，通过GRIT的统一，对于长文档，检索增强生成（RAG）的速度提高了60%以上，不再需要单独的检索和生成模型。模型、代码等可以在https://github.com/ContextualAI/gritlm 免费获取。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"NLP\",\n  \"标签\": [\n    \"语言模型\",\n    \"文本生成\",\n    \"文本嵌入\",\n    \"GRIT\",\n    \"Massive Text Embedding Benchmark\",\n    \"Retrieval-Augmented Generation\",\n    \"开源\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "NLP",
    "标签": [
      "语言模型",
      "文本生成",
      "文本嵌入",
      "GRIT",
      "Massive Text Embedding Benchmark",
      "Retrieval-Augmented Generation",
      "开源"
    ]
  }
}