{
  "id": "2403.07750v1",
  "title": "Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings",
  "pdf_url": "http://arxiv.org/pdf/2403.07750v1",
  "raw_tldr": "动机\t创建高质量的人工标注的图像-文字数据集在视觉-语言模型（VLMs）的发展中呈现出显著的瓶颈。我们提出了一种新颖的方法，利用大型语言模型（LLMs）和图像生成模型的优势，创建合成的图像-文字对，以高效和有效地训练VLM。\n方法\t我们的方法采用预训练的文本到图像模型，从LLM生成的标题开始合成图像嵌入。然后使用这些合成对来训练VLM。通过大量实验来证明我们的方法。\n结果\tVLM使用合成数据训练展现出与使用人工注释数据训练的模型相当的性能，同时只需一小部分数据。特别是，通过使用合成数据集增强，我们的性能超过基线17%。此外，我们展示了在图像嵌入空间合成比在像素空间快25%。这项研究介绍了一种生成大规模、可定制图像数据集的有前景的技术，从而提高了VLM的性能和在各个领域的适用性，同时提高了数据效率和资源利用率。",
  "tldr": {
    "动机": "创建高质量的人工标注的图像-文字数据集在视觉-语言模型（VLMs）的发展中呈现出显著的瓶颈。我们提出了一种新颖的方法，利用大型语言模型（LLMs）和图像生成模型的优势，创建合成的图像-文字对，以高效和有效地训练VLM。",
    "方法": "我们的方法采用预训练的文本到图像模型，从LLM生成的标题开始合成图像嵌入。然后使用这些合成对来训练VLM。通过大量实验来证明我们的方法。",
    "结果": "VLM使用合成数据训练展现出与使用人工注释数据训练的模型相当的性能，同时只需一小部分数据。特别是，通过使用合成数据集增强，我们的性能超过基线17%。此外，我们展示了在图像嵌入空间合成比在像素空间快25%。这项研究介绍了一种生成大规模、可定制图像数据集的有前景的技术，从而提高了VLM的性能和在各个领域的适用性，同时提高了数据效率和资源利用率。"
  },
  "summary_cn": "创建高质量的人工标注的图像-文字数据集在视觉-语言模型（VLMs）的发展中呈现出显著的瓶颈。我们提出了一种新颖的方法，利用大型语言模型（LLMs）和图像生成模型的优势，创建合成的图像-文字对，以实现VLM训练的高效性和有效性。我们的方法采用预训练一个文本到图像的模型，从LLM生成的标题开始合成图像嵌入。然后使用这些合成对来训练VLM。广泛的实验表明，使用合成数据训练的VLM在图像标题生成方面展现出与使用纯人工注释数据训练的模型相当的性能，同时只需使用一小部分数据。特别是，通过使用合成数据集增强，我们的性能超过了基线17%。此外，我们展示了在图像嵌入空间合成比在像素空间快25%。这项研究介绍了一种生成大规模、可定制图像数据集的有前景的技术，从而提高了VLM的性能和在各个领域的广泛适用性，所有这些都提高了数据效率和资源利用率。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"Visual-Language Models\",\n    \"Large Language Models\",\n    \"Image Generation\",\n    \"Synthetic Data\",\n    \"Image Captioning\",\n    \"Data Efficiency\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "Visual-Language Models",
      "Large Language Models",
      "Image Generation",
      "Synthetic Data",
      "Image Captioning",
      "Data Efficiency"
    ]
  }
}