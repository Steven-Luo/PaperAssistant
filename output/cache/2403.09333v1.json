{
  "id": "2403.09333v1",
  "title": "Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring",
  "pdf_url": "http://arxiv.org/pdf/2403.09333v1",
  "raw_tldr": "动机\t大型视觉语言模型虽然实现了细粒度的对象感知，但图像分辨率的限制仍然是超越复杂和密集场景中任务特定专家性能的重大障碍。这种限制进一步限制了模型在GUI代理、计数等领域实现细腻的视觉和语言指代的潜力。\n方法\t我们引入了一个统一的高分辨率通用模型Griffon v2，通过设计一个简单轻量的下采样投影器来有效提升图像分辨率，克服大型语言模型中的输入令牌限制。此设计本质上保留了完整的上下文和细节，并显著提高了多模态感知能力，尤其是对小物体。此外，我们还通过一个即插即用的视觉词法器为模型装备了视觉-语言共指能力，使其能够与灵活的目标图像、自由形式的文本甚至坐标进行用户友好的交互。\n结果\tGriffon v2能够通过视觉和文本指代定位任何感兴趣的对象，在REC、短语定位和REG任务上实现了最先进的性能，并在对象检测和对象计数方面超越了专家模型。",
  "tldr": {
    "动机": "大型视觉语言模型虽然实现了细粒度的对象感知，但图像分辨率的限制仍然是超越复杂和密集场景中任务特定专家性能的重大障碍。这种限制进一步限制了模型在GUI代理、计数等领域实现细腻的视觉和语言指代的潜力。",
    "方法": "我们引入了一个统一的高分辨率通用模型Griffon v2，通过设计一个简单轻量的下采样投影器来有效提升图像分辨率，克服大型语言模型中的输入令牌限制。此设计本质上保留了完整的上下文和细节，并显著提高了多模态感知能力，尤其是对小物体。此外，我们还通过一个即插即用的视觉词法器为模型装备了视觉-语言共指能力，使其能够与灵活的目标图像、自由形式的文本甚至坐标进行用户友好的交互。",
    "结果": "Griffon v2能够通过视觉和文本指代定位任何感兴趣的对象，在REC、短语定位和REG任务上实现了最先进的性能，并在对象检测和对象计数方面超越了专家模型。"
  },
  "summary_cn": "大型视觉语言模型已经实现了细粒度的对象感知，但图像分辨率的限制仍然是超越复杂和密集场景中任务特定专家性能的重大障碍。这种限制进一步限制了模型在GUI代理、计数等领域实现细腻的视觉和语言指代的潜力。为了解决这个问题，我们引入了一个统一的高分辨率通用模型，Griffon v2，使得使用视觉和文本提示灵活地指代对象成为可能。为了有效地提高图像分辨率，我们设计了一个简单轻量的下采样投影器，以克服大型语言模型中的输入令牌约束。这种设计本质上保留了完整的上下文和细节，并显著提高了特别是对小物体的多模态感知能力。在此基础上，我们进一步通过一个即插即用的视觉词法器为模型装备了视觉-语言共指能力。它使得与灵活的目标图像、自由形式的文本甚至坐标的用户友好交互成为可能。实验表明，Griffon v2能够通过视觉和文本指代定位任何感兴趣的对象，在REC、短语定位和REG任务上达到最先进的性能，并且在对象检测和对象计数方面超越了专家模型。数据、代码和模型将在https://github.com/jefferyZhan/Griffon上发布。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"视觉语言模型\",\n    \"高分辨率\",\n    \"对象感知\",\n    \"GUI代理\",\n    \"计数\",\n    \"多模态感知\",\n    \"视觉-语言共指\",\n    \"目标检测\",\n    \"对象计数\",\n    \"状态艺术性能\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "视觉语言模型",
      "高分辨率",
      "对象感知",
      "GUI代理",
      "计数",
      "多模态感知",
      "视觉-语言共指",
      "目标检测",
      "对象计数",
      "状态艺术性能"
    ]
  }
}