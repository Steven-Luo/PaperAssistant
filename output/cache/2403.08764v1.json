{
  "id": "2403.08764v1",
  "title": "VLOGGER: Multimodal Diffusion for Embodied Avatar Synthesis",
  "pdf_url": "http://arxiv.org/pdf/2403.08764v1",
  "raw_tldr": "动机\t我们提出了VLOGGER，这是一种从单张人物图像出发，通过音频驱动生成人物视频的方法，该方法基于最近生成式扩散模型的成功。与以往的工作相比，我们的方法不需要针对每个人进行训练，不依赖于面部检测和裁剪，能够生成完整的图像（不仅仅是面部或嘴唇），并考虑了广泛的场景（例如可见的躯干或多样的主体身份），这对于正确合成交流的人类至关重要。\n方法\t我们的方法包括1）一个随机人体到3D运动的扩散模型，和2）一种新颖的基于扩散的架构，该架构通过空间和时间控制增强了文本到图像模型。这支持生成可通过人脸和身体的高级表示轻松控制的高质量可变长度视频。我们还策划了MENTOR，一个新的、具有3D姿态和表情注释的多样化数据集，其规模是之前数据集的一个数量级（800,000个身份），并包含动态手势，我们在此数据集上训练和细化我们的主要技术贡献。\n结果\tVLOGGER在三个公共基准测试中超越了最先进的方法，考虑到图像质量、身份保留和时间一致性，同时还生成了上半身手势。我们通过多个多样性指标分析了VLOGGER的性能，显示出我们的架构选择和使用MENTOR对于大规模训练一个公平和无偏见的模型是有益的。最后，我们展示了在视频编辑和个性化方面的应用。",
  "tldr": {
    "动机": "我们提出了VLOGGER，这是一种从单张人物图像出发，通过音频驱动生成人物视频的方法，该方法基于最近生成式扩散模型的成功。与以往的工作相比，我们的方法不需要针对每个人进行训练，不依赖于面部检测和裁剪，能够生成完整的图像（不仅仅是面部或嘴唇），并考虑了广泛的场景（例如可见的躯干或多样的主体身份），这对于正确合成交流的人类至关重要。",
    "方法": "我们的方法包括1）一个随机人体到3D运动的扩散模型，和2）一种新颖的基于扩散的架构，该架构通过空间和时间控制增强了文本到图像模型。这支持生成可通过人脸和身体的高级表示轻松控制的高质量可变长度视频。我们还策划了MENTOR，一个新的、具有3D姿态和表情注释的多样化数据集，其规模是之前数据集的一个数量级（800,000个身份），并包含动态手势，我们在此数据集上训练和细化我们的主要技术贡献。",
    "结果": "VLOGGER在三个公共基准测试中超越了最先进的方法，考虑到图像质量、身份保留和时间一致性，同时还生成了上半身手势。我们通过多个多样性指标分析了VLOGGER的性能，显示出我们的架构选择和使用MENTOR对于大规模训练一个公平和无偏见的模型是有益的。最后，我们展示了在视频编辑和个性化方面的应用。"
  },
  "summary_cn": "我们提出了VLOGGER，这是一种从单张人物图像出发，通过音频驱动的人物视频生成方法，该方法建立在最近生成式扩散模型的成功基础上。我们的方法包括：1) 一个随机人体到3D运动的扩散模型；2) 一种新颖的基于扩散的架构，该架构通过空间和时间控制增强了文本到图像的模型。这支持生成可变长度的高质量视频，可以通过人脸和身体的高级表示轻松控制。与以往的工作不同，我们的方法不需要针对每个人进行训练，不依赖于面部检测和裁剪，生成完整的图像（不仅仅是面部或嘴唇），并考虑了广泛的场景（例如，可见的躯干或多样的主体身份），这对于正确合成交流的人类至关重要。我们还策划了MENTOR，一个新的、多样化的数据集，带有3D姿态和表情注释，其规模比以前的数据集大一个数量级（800,000个身份），并包含动态手势，我们在此数据集上训练并验证我们的主要技术贡献。VLOGGER在三个公共基准测试中超越了最先进的方法，考虑到图像质量、身份保留和时间一致性，同时还生成了上半身手势。我们根据多个多样性指标分析了VLOGGER的性能，显示我们的架构选择和使用MENTOR在大规模训练一个公平无偏见的模型方面的好处。最后，我们展示了在视频编辑和个性化方面的应用。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"CV\",\n  \"标签\": [\n    \"audio-driven human video generation\",\n    \"generative diffusion models\",\n    \"3d motion\",\n    \"text-to-image models\",\n    \"video generation\",\n    \"dataset curation\",\n    \"identity preservation\",\n    \"temporal consistency\",\n    \"video editing\",\n    \"personalization\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "CV",
    "标签": [
      "audio-driven human video generation",
      "generative diffusion models",
      "3d motion",
      "text-to-image models",
      "video generation",
      "dataset curation",
      "identity preservation",
      "temporal consistency",
      "video editing",
      "personalization"
    ]
  }
}