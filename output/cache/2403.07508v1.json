{
  "id": "2403.07508v1",
  "title": "MoAI: Mixture of All Intelligence for Large Language and Vision Models",
  "pdf_url": "http://arxiv.org/pdf/2403.07508v1",
  "raw_tldr": "动机\t当前的大型语言和视觉模型(LLVMs)忽略了专业计算机视觉(CV)模型在视觉感知任务中提供的详细和全面的现实世界场景理解，依赖于其大型语言模型(LLM)的大容量和突现能力。\n方法\t提出了一种新的LLVM，名为MoAI，它利用来自外部分割、检测、场景图生成(SGG)和光学字符识别(OCR)模型输出的辅助视觉信息。MoAI通过两个新引入的模块操作：MoAI-Compressor和MoAI-Mixer，分别用于压缩和混合视觉特征、辅助特征和语言特征。\n结果\tMoAI在多个零样本视觉语言(VL)任务中显著超越了开源和闭源的LLVMs，特别是在与现实世界场景理解相关的任务中，如对象存在、位置、关系和OCR，而且没有增加模型大小或额外的视觉指令调整数据集。",
  "tldr": {
    "动机": "当前的大型语言和视觉模型(LLVMs)忽略了专业计算机视觉(CV)模型在视觉感知任务中提供的详细和全面的现实世界场景理解，依赖于其大型语言模型(LLM)的大容量和突现能力。",
    "方法": "提出了一种新的LLVM，名为MoAI，它利用来自外部分割、检测、场景图生成(SGG)和光学字符识别(OCR)模型输出的辅助视觉信息。MoAI通过两个新引入的模块操作：MoAI-Compressor和MoAI-Mixer，分别用于压缩和混合视觉特征、辅助特征和语言特征。",
    "结果": "MoAI在多个零样本视觉语言(VL)任务中显著超越了开源和闭源的LLVMs，特别是在与现实世界场景理解相关的任务中，如对象存在、位置、关系和OCR，而且没有增加模型大小或额外的视觉指令调整数据集。"
  },
  "summary_cn": "大型语言模型（LLMs）和指令调优的兴起导致了当前的指令调优大型语言和视觉模型（LLVMs）趋势。这一趋势涉及到精心策划大量针对特定目标的指令调优数据集，或者扩大LLVMs以处理大量的视觉语言（VL）数据。然而，当前的LLVMs忽略了专门的计算机视觉（CV）模型在视觉感知任务中，如分割、检测、场景图生成（SGG）和光学字符识别（OCR），所能提供的详细和全面的现实世界场景理解。相反，现有的LLVMs主要依赖于它们LLM主干的大容量和新兴能力。因此，我们提出了一种新的LLVM，即智能混合体（MoAI），它利用从外部分割、检测、SGG和OCR模型的输出中获得的辅助视觉信息。MoAI通过两个新引入的模块运作：MoAI-压缩器和MoAI-混合器。在将外部CV模型的输出转化为文字后，MoAI-压缩器对它们进行对齐和压缩，以有效利用相关的辅助视觉信息进行VL任务。然后，MoAI-混合器通过利用专家混合的概念，将三种智能（1）视觉特征，（2）来自外部CV模型的辅助特征，和（3）语言特征混合在一起。通过这种整合，MoAI在许多零样本VL任务中显著优于开源和闭源的LLVMs，特别是那些与现实世界场景理解相关的任务，如物体存在、位置、关系和OCR，而无需增大模型大小或策划额外的视觉指令调优数据集。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"大型语言模型\",\n    \"指令调整\",\n    \"语言和视觉模型\",\n    \"计算机视觉\",\n    \"场景理解\",\n    \"分割\",\n    \"检测\",\n    \"场景图生成\",\n    \"光学字符识别\",\n    \"混合专家模型\",\n    \"零样本学习\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "大型语言模型",
      "指令调整",
      "语言和视觉模型",
      "计算机视觉",
      "场景理解",
      "分割",
      "检测",
      "场景图生成",
      "光学字符识别",
      "混合专家模型",
      "零样本学习"
    ]
  }
}