{
  "id": "2403.07815v1",
  "title": "Chronos: Learning the Language of Time Series",
  "pdf_url": "http://arxiv.org/pdf/2403.07815v1",
  "raw_tldr": "动机\t我们引入Chronos，这是一个简单而有效的预训练概率时间序列模型框架，旨在通过利用多样化领域的时间序列数据，提高未见预测任务的零样本准确性，简化预测流程。\n方法\tChronos通过缩放和量化将时间序列值转换为固定词汇表中的标记，并利用交叉熵损失在这些标记化的时间序列上训练现有的基于变压器的语言模型架构。我们在公开可用的大型数据集合上，以及我们通过高斯过程生成的合成数据集上，预训练了基于T5家族的Chronos模型（参数范围从20M到710M）。\n结果\t在包含42个数据集的综合基准测试中，与经典的局部模型和深度学习方法相比，Chronos模型：(a)在训练语料库中的数据集上显著优于其他方法；(b)在新数据集上的零样本性能与专门训练的方法相当，有时甚至更优。",
  "tldr": {
    "动机": "我们引入Chronos，这是一个简单而有效的预训练概率时间序列模型框架，旨在通过利用多样化领域的时间序列数据，提高未见预测任务的零样本准确性，简化预测流程。",
    "方法": "Chronos通过缩放和量化将时间序列值转换为固定词汇表中的标记，并利用交叉熵损失在这些标记化的时间序列上训练现有的基于变压器的语言模型架构。我们在公开可用的大型数据集合上，以及我们通过高斯过程生成的合成数据集上，预训练了基于T5家族的Chronos模型（参数范围从20M到710M）。",
    "结果": "在包含42个数据集的综合基准测试中，与经典的局部模型和深度学习方法相比，Chronos模型：(a)在训练语料库中的数据集上显著优于其他方法；(b)在新数据集上的零样本性能与专门训练的方法相当，有时甚至更优。"
  },
  "summary_cn": "我们介绍了Chronos，一个简单而有效的预训练概率时间序列模型框架。Chronos通过缩放和量化将时间序列值转换为固定词汇表中的标记，并通过交叉熵损失在这些标记化的时间序列上训练现有的基于变换器的语言模型架构。我们基于T5家族（参数范围从20M到710M）预训练了Chronos模型，在大量公开可用的数据集上进行了训练，同时补充了我们通过高斯过程生成的合成数据集以提高泛化能力。在一个包含42个数据集的综合基准测试中，涵盖了经典的局部模型和深度学习方法，我们展示了Chronos模型：(a) 在训练语料库中包含的数据集上显著优于其他方法；以及(b) 在新数据集上具有可比较的，偶尔甚至更优的零样本性能，相对于那些专门针对这些数据集训练的方法。我们的结果表明，Chronos模型可以利用来自不同领域的时间序列数据，在未见过的预测任务上提高零样本准确性，将预训练模型定位为极大简化预测流程的有效工具。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"Machine Learning\",\n  \"标签\": [\n    \"预训练模型\",\n    \"时间序列\",\n    \"Transformer\",\n    \"T5\",\n    \"概率模型\",\n    \"零样本学习\",\n    \"预测\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "Machine Learning",
    "标签": [
      "预训练模型",
      "时间序列",
      "Transformer",
      "T5",
      "概率模型",
      "零样本学习",
      "预测"
    ]
  }
}