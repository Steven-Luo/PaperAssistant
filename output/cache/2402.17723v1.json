{
  "id": "2402.17723v1",
  "raw_tldr": "动机\t视频和音频内容创作是电影行业和专业用户的核心技术。现有的基于扩散的方法分别处理视频和音频生成，这阻碍了技术从学术界向工业界的转移。本工作旨在填补这一空缺，提出了一个精心设计的基于优化的框架，用于跨视觉-音频和联合视觉-音频生成。\n方法\t我们提出了一个多模态潜在对齐器，它与预训练的ImageBind模型一起工作。该潜在对齐器在核心上与分类器引导相似，引导扩散去噪过程在推理时进行。通过精心设计的优化策略和损失函数，我们将现有的强大模型通过共享的潜在表示空间进行桥接。\n结果\t我们的方法在联合视频-音频生成、视觉引导音频生成和音频引导视觉生成任务上展示了优越的性能。",
  "tldr": {
    "动机": "视频和音频内容创作是电影行业和专业用户的核心技术。现有的基于扩散的方法分别处理视频和音频生成，这阻碍了技术从学术界向工业界的转移。本工作旨在填补这一空缺，提出了一个精心设计的基于优化的框架，用于跨视觉-音频和联合视觉-音频生成。",
    "方法": "我们提出了一个多模态潜在对齐器，它与预训练的ImageBind模型一起工作。该潜在对齐器在核心上与分类器引导相似，引导扩散去噪过程在推理时进行。通过精心设计的优化策略和损失函数，我们将现有的强大模型通过共享的潜在表示空间进行桥接。",
    "结果": "我们的方法在联合视频-音频生成、视觉引导音频生成和音频引导视觉生成任务上展示了优越的性能。"
  },
  "summary_cn": "视频和音频内容的创作是电影行业和专业用户的核心技术。最近，现有的基于扩散的方法分别处理视频和音频生成，这阻碍了技术从学术界向工业界的转移。在这项工作中，我们旨在填补这一空缺，提出了一个精心设计的基于优化的框架，用于跨视觉-音频和联合视觉-音频生成。我们观察到现成的视频或音频生成模型具有强大的生成能力。因此，我们提出不是从头开始训练庞大的模型，而是将现有的强大模型通过一个共享的潜在表示空间连接起来。具体来说，我们提出了一个带有预训练的ImageBind模型的多模态潜在对齐器。我们的潜在对齐器与分类器引导共享相似的核心，该引导在推理时指导扩散去噪过程。通过精心设计的优化策略和损失函数，我们展示了我们的方法在联合视频-音频生成、视觉引导音频生成和音频引导视觉生成任务上的卓越性能。项目网站可以在 https://yzxing87.github.io/Seeing-and-Hearing/ 找到。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"视频生成\",\n    \"音频生成\",\n    \"跨视觉音频生成\",\n    \"联合视觉音频生成\",\n    \"优化框架\",\n    \"多模态对齐\",\n    \"扩散模型\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "视频生成",
      "音频生成",
      "跨视觉音频生成",
      "联合视觉音频生成",
      "优化框架",
      "多模态对齐",
      "扩散模型"
    ]
  }
}