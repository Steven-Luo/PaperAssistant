{
  "id": "2402.14327v1",
  "raw_tldr": "#动机\nTransformer基于视觉模型通常将图像分割成固定大小的正方形块作为输入单元，这种方式缺乏对图像内容的适应性，并忽视了固有的像素分组结构。为了解决这一问题，受到语言模型中广泛采用的子词(token)化启发，提出了一种在子对象级别上的图像分词器。\n\n#方法\n提出的方法首先使用序列到序列的自编码器(SeqAE)将不同大小和形状的子对象段压缩成紧凑的嵌入向量，然后将这些子对象嵌入向量输入到大型语言模型中进行视觉语言学习。\n\n#结果\n实证结果表明，与传统的块级(tokenization)相比，我们的子对象级别的分词(tokenization)显著促进了将图像翻译成对象和属性描述的高效学习。代码和模型将在https://github.com/ChenDelong1999/subobjects 上开源。",
  "summary_cn": "基于Transformer的视觉模型通常将图像分割成固定大小的正方形块作为输入单元，这种做法缺乏对图像内容的适应性，并忽略了固有的像素分组结构。受到语言模型中广泛采用的子词(token)分割法的启发，我们提出了一种在子对象级别上进行图像分割的方法，其中子对象由语义上有意义的图像段组成，这些图像段是通过分割模型（例如，分割任何事物的模型）获得的。为了实现基于子对象分割的学习系统，我们首先引入了一个序列到序列的自编码器(SeqAE)，以将不同大小和形状的子对象段压缩成紧凑的嵌入向量，然后将这些子对象嵌入向量输入到一个大型的视觉语言学习模型中。实证结果表明，与传统的块级分割相比，我们的子对象级分割显著地促进了将图像转换为对象和属性描述的学习效率。代码和模型将在https://github.com/ChenDelong1999/subobjects 上开源。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\"Transformer\", \"视觉模型\", \"子词(token)化\", \"图像分割\", \"序列到序列自编码器\", \"视觉语言学习\"]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "Transformer",
      "视觉模型",
      "子词(token)化",
      "图像分割",
      "序列到序列自编码器",
      "视觉语言学习"
    ]
  },
  "tldr": {
    "": "结果",
    "Transformer基于视觉模型通常将图像分割成固定大小的正方形块作为输入单元，这种方式缺乏对图像内容的适应性，并忽视了固有的像素分组结构。为了解决这一问题，受到语言模型中广泛采用的子词(token)化启发，提出了一种在子对象级别上的图像分词器。": "",
    "提出的方法首先使用序列到序列的自编码器(SeqAE)将不同大小和形状的子对象段压缩成紧凑的嵌入向量，然后将这些子对象嵌入向量输入到大型语言模型中进行视觉语言学习。": "",
    "实证结果表明，与传统的块级(tokenization)相比，我们的子对象级别的分词(tokenization)显著促进了将图像翻译成对象和属性描述的高效学习。代码和模型将在https://github.com/ChenDelong1999/subobjects 上开源。": "",
    "动机": "",
    "方法": "",
    "结果": ""
  }
}