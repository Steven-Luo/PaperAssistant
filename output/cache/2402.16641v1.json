{
  "id": "2402.16641v1",
  "raw_tldr": "动机\t比较设置（例如成对选择、列表排名）已被广泛采用于图像质量评估（IQA）的主观研究中，因为它本质上在不同观察者之间标准化了评估标准，并提供了更明确的响应。为了进一步推进视觉质量比较进入开放式设置，本工作扩展了新兴的大型多模态模型（LMMs）的边界。\n方法\t提出了Co-Instruct，并收集了Co-Instruct-562K数据集，该数据集来自两个来源：（a）LMM合并的单一图像质量描述，（b）GPT-4V“教师”对未标记数据的响应。此外，提出了MICBench，这是第一个针对LMMs的多图像比较基准。\n结果\tCo-Instruct不仅比现有的最先进的开源LMMs的准确率高出30%，而且还在现有相关基准和提出的MICBench上超过了其“教师”GPT-4V。",
  "tldr": {
    "动机": "比较设置（例如成对选择、列表排名）已被广泛采用于图像质量评估（IQA）的主观研究中，因为它本质上在不同观察者之间标准化了评估标准，并提供了更明确的响应。为了进一步推进视觉质量比较进入开放式设置，本工作扩展了新兴的大型多模态模型（LMMs）的边界。",
    "方法": "提出了Co-Instruct，并收集了Co-Instruct-562K数据集，该数据集来自两个来源：（a）LMM合并的单一图像质量描述，（b）GPT-4V“教师”对未标记数据的响应。此外，提出了MICBench，这是第一个针对LMMs的多图像比较基准。",
    "结果": "Co-Instruct不仅比现有的最先进的开源LMMs的准确率高出30%，而且还在现有相关基准和提出的MICBench上超过了其“教师”GPT-4V。"
  },
  "summary_cn": "比较设置（例如成对选择、列表排序）已被广泛采用于图像质量评估（IQA）的主观研究中，因为它本质上在不同观察者之间标准化了评估标准，并提供了更明确的响应。在这项工作中，我们扩展了新兴的大型多模态模型（LMMs）的边界，以进一步将视觉质量比较推进到开放式设置，即：1）可以回应关于质量比较的开放范围问题；2）可以提供超出直接答案的详细推理。为此，我们提出了Co-Instruct。为了训练这种首创的开源开放式视觉质量比较器，我们收集了Co-Instruct-562K数据集，来源于两个方面：（a）LMM合并的单一图像质量描述，（b）GPT-4V“教师”对未标记数据的响应。此外，为了更好地评估这一设置，我们提出了MICBench，这是针对LMMs的首个多图像比较基准测试。我们证明，Co-Instruct不仅比现有的最先进的开源LMMs的准确率高出30%，而且在现有相关基准测试和我们提出的MICBench上都超过了GPT-4V（它的教师）。我们的模型发布在https://huggingface.co/q-future/co-instruct。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"图像质量评估\",\n    \"大型多模态模型\",\n    \"视觉质量比较\",\n    \"开放式问题\",\n    \"数据集\",\n    \"基准测试\",\n    \"模型性能\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "图像质量评估",
      "大型多模态模型",
      "视觉质量比较",
      "开放式问题",
      "数据集",
      "基准测试",
      "模型性能"
    ]
  }
}