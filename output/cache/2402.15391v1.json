{
  "id": "2402.15391v1",
  "raw_tldr": "#动机：为了创造一个能够生成无限多样化、可通过文本、合成图像、照片甚至素描描述的可控动作虚拟世界的交互环境，而且这个环境是通过未标记的互联网视频以无监督方式训练的。\n\n#方法：Genie模型采用了一个时空视频分词器、一个自回归动态模型以及一个简单且可扩展的潜在动作模型，总共拥有11B参数，可以被视为一个基础世界模型。\n\n#结果：Genie使用户能够在生成的环境中逐帧进行交互操作，尽管在训练过程中没有使用任何真实动作标签或其他特定领域的要求。此外，所学习的潜在动作空间促进了从未见过的视频中模仿行为的代理训练，为未来训练通用代理开辟了道路。",
  "tldr": {
    "": "结果：Genie使用户能够在生成的环境中逐帧进行交互操作，尽管在训练过程中没有使用任何真实动作标签或其他特定领域的要求。此外，所学习的潜在动作空间促进了从未见过的视频中模仿行为的代理训练，为未来训练通用代理开辟了道路。",
    "动机": "",
    "方法": "",
    "结果": ""
  },
  "summary_cn": "我们介绍了Genie，这是第一个从未标记的互联网视频中以无监督方式训练出的生成式交互环境。该模型可以被提示生成无尽种类的、通过文本、合成图像、照片甚至草图描述的可控动作的虚拟世界。作为一个拥有110亿参数的基础世界模型，Genie包括了一个时空视频分词器、一个自回归动态模型以及一个简单且可扩展的潜在动作模型。尽管在训练过程中没有使用任何真实动作标签或世界模型文献中通常发现的其他领域特定要求，Genie使用户能够在生成的环境中逐帧进行操作。此外，所学习的潜在动作空间促进了训练代理以模仿未见视频中的行为，为训练未来的通用代理开辟了道路。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"生成模型\",\n    \"交互环境\",\n    \"无监督学习\",\n    \"视频处理\",\n    \"虚拟世界生成\",\n    \"行为控制\",\n    \"基础世界模型\",\n    \"时空视频分析\",\n    \"自回归动态模型\",\n    \"潜在行为模型\",\n    \"行为模仿\",\n    \"智能体训练\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "生成模型",
      "交互环境",
      "无监督学习",
      "视频处理",
      "虚拟世界生成",
      "行为控制",
      "基础世界模型",
      "时空视频分析",
      "自回归动态模型",
      "潜在行为模型",
      "行为模仿",
      "智能体训练"
    ]
  }
}