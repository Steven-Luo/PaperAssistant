{
  "id": "2402.16837v1",
  "raw_tldr": "动机\t我们研究大型语言模型（LLMs）是否能够通过复杂提示进行潜在的多跳推理，例如“'Superstition'的歌手的母亲是”。\n方法\t通过分析LLM识别桥接实体（如“'Superstition'的歌手”为史蒂夫·旺达）并使用其对史蒂夫·旺达母亲的知识完成提示的两个步骤，来寻找潜在多跳推理的证据。测试改变提示以间接提及桥接实体是否增加了LLM内部对桥接实体的回忆，以及这种回忆是否使LLM更好地利用其对桥接实体的知识。\n结果\t发现对于某些关系类型的提示，存在强有力的潜在多跳推理证据，这种推理路径在超过80%的提示中被使用。但是，这种利用高度依赖上下文，在不同类型的提示中变化很大。平均而言，对于第二跳和完整的多跳遍历的证据相对温和，仅在第一跳中是显著的。此外，随着模型大小的增加，第一跳推理呈现出明显的规模趋势，但第二跳推理并非如此。",
  "tldr": {
    "动机": "我们研究大型语言模型（LLMs）是否能够通过复杂提示进行潜在的多跳推理，例如“'Superstition'的歌手的母亲是”。",
    "方法": "通过分析LLM识别桥接实体（如“'Superstition'的歌手”为史蒂夫·旺达）并使用其对史蒂夫·旺达母亲的知识完成提示的两个步骤，来寻找潜在多跳推理的证据。测试改变提示以间接提及桥接实体是否增加了LLM内部对桥接实体的回忆，以及这种回忆是否使LLM更好地利用其对桥接实体的知识。",
    "结果": "发现对于某些关系类型的提示，存在强有力的潜在多跳推理证据，这种推理路径在超过80%的提示中被使用。但是，这种利用高度依赖上下文，在不同类型的提示中变化很大。平均而言，对于第二跳和完整的多跳遍历的证据相对温和，仅在第一跳中是显著的。此外，随着模型大小的增加，第一跳推理呈现出明显的规模趋势，但第二跳推理并非如此。"
  },
  "summary_cn": "我们研究大型语言模型（LLMs）是否能够隐性地进行多跳推理，以处理复杂的提示，例如“‘迷信’的歌手的母亲是”。我们寻找隐性推理路径的证据，其中LLM（1）隐性地识别“‘迷信’的歌手”为史蒂夫·旺达，作为桥接实体；（2）利用其对史蒂夫·旺达母亲的知识来完成提示。我们分别分析这两个跳跃，并将它们的共同出现视为隐性多跳推理的指标。对于第一个跳跃，我们测试将提示改为间接提及桥接实体而不是其他任何实体，是否会增加LLM内部对桥接实体的回忆。对于第二个跳跃，我们测试增加这种回忆是否会使LLM更好地利用它所知道的关于桥接实体的信息。我们发现对于某些关系类型的提示，有强有力的隐性多跳推理证据，这种推理路径在超过80%的提示中被使用。然而，利用高度依赖上下文，在不同类型的提示中变化。此外，平均而言，对于第二跳和完整的多跳遍历的证据相当中等，仅对第一跳而言是实质性的。此外，我们发现随着模型大小的增加，第一跳推理呈现出明显的规模化趋势，但第二跳推理则没有。我们的实验发现提示了未来LLMs的发展和应用面临的潜在挑战和机遇。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"NLP\",\n  \"标签\": [\n    \"Large Language Models\",\n    \"multi-hop reasoning\",\n    \"complex prompts\",\n    \"latent reasoning\",\n    \"model scaling\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "NLP",
    "标签": [
      "Large Language Models",
      "multi-hop reasoning",
      "complex prompts",
      "latent reasoning",
      "model scaling"
    ]
  }
}