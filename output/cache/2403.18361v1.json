{
  "id": "2403.18361v1",
  "title": "ViTAR: Vision Transformer with Any Resolution",
  "pdf_url": "http://arxiv.org/pdf/2403.18361v1",
  "raw_tldr": "动机：为了解决视觉变换器（ViTs）在处理不同于训练时分辨率的图像时性能下降的问题，提高其在不同图像分辨率上的可扩展性。\n方法：提出了一个新颖的动态分辨率调整模块，该模块采用单一变换器块设计，实现高效的增量标记整合，并引入了模糊位置编码，以在多分辨率下提供一致的位置感知，防止过拟合到任何单一训练分辨率。\n结果：所提出的模型ViTAR在1120x1120分辨率下达到了83.3%的top-1准确率，在4032x4032分辨率下达到了80.4%的准确率，同时降低了计算成本，并且在实例和语义分割等下游任务中表现出色，可以轻松与像Masked AutoEncoder这样的自监督学习技术结合使用。",
  "tldr": {
    "动机：为了解决视觉变换器（ViTs）在处理不同于训练时分辨率的图像时性能下降的问题，提高其在不同图像分辨率上的可扩展性。": "",
    "方法：提出了一个新颖的动态分辨率调整模块，该模块采用单一变换器块设计，实现高效的增量标记整合，并引入了模糊位置编码，以在多分辨率下提供一致的位置感知，防止过拟合到任何单一训练分辨率。": "",
    "结果：所提出的模型ViTAR在1120x1120分辨率下达到了83.3%的top-1准确率，在4032x4032分辨率下达到了80.4%的准确率，同时降低了计算成本，并且在实例和语义分割等下游任务中表现出色，可以轻松与像Masked AutoEncoder这样的自监督学习技术结合使用。": "",
    "动机": "",
    "方法": "",
    "结果": ""
  },
  "summary_cn": "本文解决了视觉变换器（Vision Transformers，简称ViTs）面临的一个重要挑战：它们在不同图像分辨率下的可扩展性受限。通常情况下，ViTs在处理与训练时不同分辨率的图像时，性能会有所下降。我们的工作引入了两个关键创新来解决这个问题。首先，我们提出了一个动态分辨率调整的新颖模块，该模块设计为使用单个变换器块，特别为了实现高效增量标记集成。其次，我们在视觉变换器中引入了模糊位置编码，以在多个分辨率下提供一致的位置感知，从而防止对任何单一训练分辨率的过拟合。我们所得到的模型ViTAR（任意分辨率的视觉变换器）展示了令人印象深刻的适应性，在1120x1120分辨率下达到83.3%的top-1准确率，在4032x4032分辨率下达到80.4%的准确率，同时还降低了计算成本。ViTAR在下游任务中也表现出强大的性能，如实例和语义分割，并且可以轻松地与自监督学习技术（如Masked AutoEncoder）结合使用。我们的工作为提高ViTs的分辨率可扩展性提供了一种成本效益高的解决方案，为更通用和高效的高分辨率图像处理铺平了道路。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"CV\",\n  \"标签\": [\"Vision Transformers\", \"ViTs\", \"图像分辨率\", \"动态分辨率调整\", \"模糊位置编码\", \"模型适应性\", \"计算成本\", \"下游任务\", \"实例分割\", \"语义分割\", \"自监督学习\", \"Masked AutoEncoder\", \"高分辨率图像处理\"]\n}\n```",
  "tag_info": {
    "主要领域": "CV",
    "标签": [
      "Vision Transformers",
      "ViTs",
      "图像分辨率",
      "动态分辨率调整",
      "模糊位置编码",
      "模型适应性",
      "计算成本",
      "下游任务",
      "实例分割",
      "语义分割",
      "自监督学习",
      "Masked AutoEncoder",
      "高分辨率图像处理"
    ]
  }
}