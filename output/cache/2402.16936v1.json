{
  "id": "2402.16936v1",
  "raw_tldr": "动机\t我们提出了一种生成3D场景的方法，这些场景被解构成其组成对象。这种解构是无监督的，仅依赖于一个大型预训练的文本到图像模型的知识。\n方法\t我们的方法是从头开始联合优化多个NeRFs（每个代表其自己的对象），以及一个组合这些对象成场景的布局集合。然后，我们鼓励这些组合场景根据图像生成器处于分布中。\n结果\t尽管方法简单，我们的方法成功地生成了分解成单个对象的3D场景，为文本到3D内容创建启用了新的能力。",
  "tldr": {
    "动机": "我们提出了一种生成3D场景的方法，这些场景被解构成其组成对象。这种解构是无监督的，仅依赖于一个大型预训练的文本到图像模型的知识。",
    "方法": "我们的方法是从头开始联合优化多个NeRFs（每个代表其自己的对象），以及一个组合这些对象成场景的布局集合。然后，我们鼓励这些组合场景根据图像生成器处于分布中。",
    "结果": "尽管方法简单，我们的方法成功地生成了分解成单个对象的3D场景，为文本到3D内容创建启用了新的能力。"
  },
  "summary_cn": "我们介绍了一种生成3D场景的方法，这些场景被解构为它们的组成对象。这种解构是无监着的，仅依赖于一个大型预训练的文本到图像模型的知识。我们的关键洞察是，通过找到3D场景的部分，这些部分在空间上重新排列后，仍然能够产生同一场景的有效配置，可以发现对象。具体来说，我们的方法从头开始联合优化多个NeRF（神经辐射场） - 每个都代表其自己的对象 - 以及一个布局集合，这些布局将这些对象合成为场景。然后，我们鼓励这些合成场景根据图像生成器处于分布中。我们展示了尽管我们的方法很简单，但成功地生成了分解为单个对象的3D场景，为文本到3D内容创建启用了新的能力。有关结果和交互式演示，请参见我们的项目页面 https://dave.ml/layoutlearning/。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"CV\",\n  \"标签\": [\"3D scene generation\", \"unsupervised learning\", \"NeRF\", \"text-to-image model\", \"object disentanglement\"]\n}\n```",
  "tag_info": {
    "主要领域": "CV",
    "标签": [
      "3D scene generation",
      "unsupervised learning",
      "NeRF",
      "text-to-image model",
      "object disentanglement"
    ]
  }
}