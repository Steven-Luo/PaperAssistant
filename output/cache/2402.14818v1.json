{
  "id": "2402.14818v1",
  "raw_tldr": "动机#为了追求更具包容性的视觉-语言模型（VLMs），本研究旨在介绍一种名为Palo的大型多语言多模态模型，该模型能够在10种主要语言中提供视觉推理能力，这些语言覆盖了全球约65%的人口。\n\n方法#本研究采用了一种半自动化的翻译方法，通过对大型语言模型进行微调，将多模态指令数据集从英语适配到目标语言，以确保高语言保真度，同时由于手动工作量最小化而具有可扩展性。此外，通过训练具有不同规模参数（1.7B、7B和13B）的模型，展示了模型的泛化能力和可扩展性。\n\n结果#与强基线相比，Palo在多种语言（特别是那些代表性较差的语言，如印地语、阿拉伯语、孟加拉语和乌尔都语）上的整体性能得到了显著提升。此外，本研究还提出了首个多语言多模态基准，用于评估未来方法在跨语言的视觉-语言推理能力。",
  "tldr": {
    "动机": "为了追求更具包容性的视觉-语言模型（VLMs），本研究旨在介绍一种名为Palo的大型多语言多模态模型，该模型能够在10种主要语言中提供视觉推理能力，这些语言覆盖了全球约65%的人口。",
    "方法": "本研究采用了一种半自动化的翻译方法，通过对大型语言模型进行微调，将多模态指令数据集从英语适配到目标语言，以确保高语言保真度，同时由于手动工作量最小化而具有可扩展性。此外，通过训练具有不同规模参数（1.7B、7B和13B）的模型，展示了模型的泛化能力和可扩展性。",
    "结果": "与强基线相比，Palo在多种语言（特别是那些代表性较差的语言，如印地语、阿拉伯语、孟加拉语和乌尔都语）上的整体性能得到了显著提升。此外，本研究还提出了首个多语言多模态基准，用于评估未来方法在跨语言的视觉-语言推理能力。"
  },
  "summary_cn": "为了追求更具包容性的视觉-语言模型（VLMs），本研究引入了一个名为\\textsc{Palo}的大型多语言多模态模型。\\textsc{Palo}在10种主要语言中提供视觉推理能力，包括英语、中文、印地语、西班牙语、法语、阿拉伯语、孟加拉语、俄语、乌尔都语和日语，这些语言总共覆盖了约50亿人口（占世界人口的65%）。我们的方法涉及使用经过微调的大型语言模型，采用半自动翻译方法将多模态指令数据集从英语适配到目标语言，从而确保高语言保真度，同时由于手动工作量最小化而允许可扩展性。引入多样化的指令集帮助我们在多种语言中提升整体性能，特别是在那些代表性不足的语言，如印地语、阿拉伯语、孟加拉语和乌尔都语。所得模型在三个规模（17亿、70亿和130亿参数）上进行训练，以展示其泛化能力和可扩展性，在与强基线相比时我们观察到了显著的改进。我们还提出了第一个多语言多模态基准测试，用于评估未来方法在跨语言的视觉-语言推理能力。代码：https://github.com/mbzuai-oryx/PALO。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\n    \"Vision-Language Models\",\n    \"Multilingual\",\n    \"Visual Reasoning\",\n    \"Large Language Model\",\n    \"Multimodal Benchmark\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "Vision-Language Models",
      "Multilingual",
      "Visual Reasoning",
      "Large Language Model",
      "Multimodal Benchmark"
    ]
  }
}