{
  "id": "2402.13753v1",
  "title": "LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens",
  "pdf_url": "http://arxiv.org/pdf/2402.13753v1",
  "raw_tldr": "动机\t大型语言模型（LLMs）中，大上下文窗口是一个受欢迎的特性。然而，由于高昂的微调成本、长文本的稀缺性以及新令牌位置引入的灾难性值，当前扩展的上下文窗口限制在大约128k令牌。\n方法\t本文介绍了LongRoPE，这是首次将预训练LLMs的上下文窗口扩展到2048k令牌，仅需最多1k的微调步骤即可在256k训练长度内维持原始短上下文窗口的性能。这通过三个关键创新实现：(i) 通过高效搜索识别并利用位置插值中的两种非均匀性，为微调提供更好的初始化并在非微调场景下实现8倍扩展；(ii) 引入一种渐进式扩展策略，首先对256k长度的LLM进行微调，然后对微调后的扩展LLM进行第二次位置插值以实现2048k上下文窗口；(iii) 在8k长度上重新调整LongRoPE以恢复短上下文窗口性能。\n结果\t在LLaMA2和Mistral的各种任务上的广泛实验证明了我们方法的有效性。通过LongRoPE扩展的模型保留了原始架构，并对位置嵌入进行了微小修改，可以重用大多数现有的优化。",
  "tldr": {
    "动机": "大型语言模型（LLMs）中，大上下文窗口是一个受欢迎的特性。然而，由于高昂的微调成本、长文本的稀缺性以及新令牌位置引入的灾难性值，当前扩展的上下文窗口限制在大约128k令牌。",
    "方法": "本文介绍了LongRoPE，这是首次将预训练LLMs的上下文窗口扩展到2048k令牌，仅需最多1k的微调步骤即可在256k训练长度内维持原始短上下文窗口的性能。这通过三个关键创新实现：(i) 通过高效搜索识别并利用位置插值中的两种非均匀性，为微调提供更好的初始化并在非微调场景下实现8倍扩展；(ii) 引入一种渐进式扩展策略，首先对256k长度的LLM进行微调，然后对微调后的扩展LLM进行第二次位置插值以实现2048k上下文窗口；(iii) 在8k长度上重新调整LongRoPE以恢复短上下文窗口性能。",
    "结果": "在LLaMA2和Mistral的各种任务上的广泛实验证明了我们方法的有效性。通过LongRoPE扩展的模型保留了原始架构，并对位置嵌入进行了微小修改，可以重用大多数现有的优化。"
  },
  "summary_cn": "大型语言模型（LLMs）中一个理想的特性是大上下文窗口。然而，由于高昂的微调成本、长文本的稀缺性以及新令牌位置引入的灾难性价值，当前扩展的上下文窗口仅限于约128k令牌。本文首次介绍了LongRoPE，它将预训练LLMs的上下文窗口扩展到了令人印象深刻的2048k令牌，同时在256k训练长度内仅需最多1k的微调步骤，同时保持了原始短上下文窗口的性能。这是通过三个关键创新实现的：（i）我们通过高效搜索识别并利用位置插值中的两种非均匀性形式，为微调提供了更好的初始化，并在非微调场景下实现了8倍的扩展；（ii）我们引入了一种渐进式扩展策略，首先对一个256k长度的LLM进行微调，然后对微调后的扩展LLM进行第二次位置插值，以实现2048k的上下文窗口；（iii）我们在8k长度上重新调整LongRoPE，以恢复短上下文窗口的性能。在LLaMA2和Mistral上针对各种任务进行的广泛实验证明了我们方法的有效性。通过LongRoPE扩展的模型保留了原始架构，并对位置嵌入进行了微小修改，可以重用大多数现有的优化。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"NLP\",\n  \"标签\": [\n    \"large language models\",\n    \"context window extension\",\n    \"positional interpolation\",\n    \"fine-tuning\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "NLP",
    "标签": [
      "large language models",
      "context window extension",
      "positional interpolation",
      "fine-tuning"
    ]
  }
}