{
  "id": "2402.14830v1",
  "raw_tldr": "动机#数学文字题解决一直是小型语言模型(SLMs)的一个复杂任务。最近的研究假设要达到GSM8K基准测试中超过80%的准确率，需要的最小模型大小为340亿参数。为了用更小的模型达到这一性能水平，研究人员通常训练SLMs生成Python代码或使用工具帮助避免计算错误，并采用集成方法，通过结合多达100个模型运行的输出来获得更准确的结果。\n\n方法#本文提出了一种基于Mistral-7B的7亿参数SLM——Orca-Math，它在不需要多次模型调用、验证器、代码执行或任何其他外部工具的情况下，在GSM8k上达到了86.81%的准确率。我们的方法包括：(1) 使用多代理设置创建的20万高质量合成数学问题数据集，代理协作创建数据；(2) 一种迭代学习技术，使SLM能够练习解决问题，接收对其解决方案的反馈，并从包含SLM解决方案和反馈的偏好对中学习。\n\n结果#Orca-Math在GSM8k的pass@1指标上，仅通过监督细调就达到了81.50%的准确率。通过迭代偏好学习，Orca-Math的准确率提高到了86.81%。Orca-Math超越了像LLAMA-2-70B、WizardMath-70B、Gemini-Pro、ChatGPT-3.5这样的大型模型，同时在使用的数据量上（成千上万个问题对比百万个问题）也显著优于其他小型模型。",
  "tldr": {
    "动机": "数学文字题解决一直是小型语言模型(SLMs)的一个复杂任务。最近的研究假设要达到GSM8K基准测试中超过80%的准确率，需要的最小模型大小为340亿参数。为了用更小的模型达到这一性能水平，研究人员通常训练SLMs生成Python代码或使用工具帮助避免计算错误，并采用集成方法，通过结合多达100个模型运行的输出来获得更准确的结果。",
    "方法": "本文提出了一种基于Mistral-7B的7亿参数SLM——Orca-Math，它在不需要多次模型调用、验证器、代码执行或任何其他外部工具的情况下，在GSM8k上达到了86.81%的准确率。我们的方法包括：(1) 使用多代理设置创建的20万高质量合成数学问题数据集，代理协作创建数据；(2) 一种迭代学习技术，使SLM能够练习解决问题，接收对其解决方案的反馈，并从包含SLM解决方案和反馈的偏好对中学习。",
    "结果": "Orca-Math在GSM8k的pass@1指标上，仅通过监督细调就达到了81.50%的准确率。通过迭代偏好学习，Orca-Math的准确率提高到了86.81%。Orca-Math超越了像LLAMA-2-70B、WizardMath-70B、Gemini-Pro、ChatGPT-3.5这样的大型模型，同时在使用的数据量上（成千上万个问题对比百万个问题）也显著优于其他小型模型。"
  },
  "summary_cn": "数学文字题解题一直被认为是小型语言模型（SLMs）的一个复杂任务。最近的一项研究假设，要在GSM8K基准测试上达到超过80%的准确率，所需的最小模型大小为340亿参数。为了用更小的模型达到这一性能水平，研究人员通常训练SLMs生成Python代码或使用工具帮助避免计算错误。此外，他们采用集成学习，将多达100次模型运行的输出组合起来，以得到更准确的结果。结果选择是通过共识、多数投票或与SLM一起使用的单独的验证器模型来完成的。集成学习提供了显著的准确性提升，但成本大幅增加，需要多次调用模型（例如，Phi-GSM使用前48名来将性能从68.2提升到81.5）。在这项工作中，我们介绍了Orca-Math，一个基于Mistral-7B的70亿参数SLM，它在不需要多次模型调用、使用验证器、代码执行或任何其他外部工具的情况下，在GSM8k上达到了86.81%的准确率。我们的方法包括以下关键要素：（1）使用多代理设置创建数据的200K数学问题的高质量合成数据集，其中代理合作创建数据，（2）一种迭代学习技术，使SLM能够练习解决问题，接收对其解决方案的反馈，并从结合了SLM解决方案和反馈的偏好对中学习。仅通过监督式微调训练时，Orca-Math在GSM8k pass@1指标上达到了81.50%。通过迭代偏好学习，Orca-Math达到了86.81% pass@1。Orca-Math超越了LLAMA-2-70B、WizardMath-70B、Gemini-Pro、ChatGPT-3.5等大得多的模型的性能。它还在使用更少的数据（成千上万 vs. 百万个问题）的同时，显著优于其他较小的模型。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"NLP\",\n  \"标签\": [\n    \"数学问题求解\",\n    \"小型语言模型\",\n    \"合成数据集\",\n    \"迭代学习\",\n    \"监督式微调\",\n    \"偏好学习\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "NLP",
    "标签": [
      "数学问题求解",
      "小型语言模型",
      "合成数据集",
      "迭代学习",
      "监督式微调",
      "偏好学习"
    ]
  }
}