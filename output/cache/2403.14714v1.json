{
  "id": "2403.14714v1",
  "title": "Compiler generated feedback for Large Language Models",
  "pdf_url": "http://arxiv.org/pdf/2403.14714v1",
  "raw_tldr": "动机\t我们引入了一种新颖的编译器优化范式，该范式利用大型语言模型和编译器反馈来优化LLVM汇编的代码大小。\n方法\t该模型接受未优化的LLVM IR作为输入，并产生优化后的IR、最佳优化通道以及未优化和优化后IR的指令计数。然后，我们使用生成的优化通道编译输入，并评估预测的指令计数是否准确，生成的IR是否可编译，以及是否与编译后的代码相对应。我们将这一反馈提供给LLM，并给予其另一个优化代码的机会。\n结果\t这种方法在原始模型的基础上，通过-Oz额外增加了0.53%的改进。尽管添加更多反馈信息看起来直观简单，但是简单的抽样技术在给定10个或更多样本时能够实现更高的性能。",
  "tldr": {
    "动机": "我们引入了一种新颖的编译器优化范式，该范式利用大型语言模型和编译器反馈来优化LLVM汇编的代码大小。",
    "方法": "该模型接受未优化的LLVM IR作为输入，并产生优化后的IR、最佳优化通道以及未优化和优化后IR的指令计数。然后，我们使用生成的优化通道编译输入，并评估预测的指令计数是否准确，生成的IR是否可编译，以及是否与编译后的代码相对应。我们将这一反馈提供给LLM，并给予其另一个优化代码的机会。",
    "结果": "这种方法在原始模型的基础上，通过-Oz额外增加了0.53%的改进。尽管添加更多反馈信息看起来直观简单，但是简单的抽样技术在给定10个或更多样本时能够实现更高的性能。"
  },
  "summary_cn": "我们引入了一种新颖的编译器优化范式，该范式利用大型语言模型（LLM）并结合编译器反馈来优化LLVM汇编代码的大小。该模型以未优化的LLVM IR为输入，生成优化后的IR、最佳优化通道以及未优化和优化后IR的指令计数。然后，我们使用生成的优化通道编译输入，并评估预测的指令计数是否准确、生成的IR是否可编译以及是否与编译后的代码相对应。我们将这一反馈提供给LLM，并给予它另一个优化代码的机会。这种方法在原始模型的基础上，通过-Oz额外增加了0.53%的改进。尽管添加更多反馈信息看起来直观，但简单的抽样技术在给定10个或更多样本的情况下，能够实现更高的性能。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"Machine Learning\",\n  \"标签\": [\"Compiler Optimization\", \"Large Language Models\", \"LLVM\", \"Code Optimization\"]\n}\n```",
  "tag_info": {
    "主要领域": "Machine Learning",
    "标签": [
      "Compiler Optimization",
      "Large Language Models",
      "LLVM",
      "Code Optimization"
    ]
  }
}