{
  "id": "2402.19479v1",
  "raw_tldr": "动机\t数据和标注的质量是下游模型质量的上限。尽管存在大量文本语料库和图文对，但高质量的视频文本数据更难收集。手动标注更耗时，因为它要求标注者观看整个视频。此外，视频具有时间维度，包含多个场景和多个动作。\n方法\t我们提出一种自动方法，利用多模态输入（如文本视频描述、字幕和单个视频帧）来建立高质量字幕的视频数据集。具体来说，我们从公开可用的HD-VILA-100M数据集中筛选出3.8M高分辨率视频，将它们分割成语义一致的视频剪辑，并应用多个跨模态教师模型为每个视频获取字幕。接着，我们在一个小的子集上微调一个检索模型，该子集中每个视频的最佳字幕是手动选出的，然后在整个数据集上使用该模型选择最佳字幕作为注释。\n结果\t我们获得了70M个视频与高质量文本字幕配对的数据集，命名为Panda-70M。我们展示了该数据集在三个下游任务上的价值：视频字幕、视频和文本检索、以及文本驱动的视频生成。在所有任务上，使用所提数据训练的模型在大多数指标上得分显著更好。",
  "tldr": {
    "动机": "数据和标注的质量是下游模型质量的上限。尽管存在大量文本语料库和图文对，但高质量的视频文本数据更难收集。手动标注更耗时，因为它要求标注者观看整个视频。此外，视频具有时间维度，包含多个场景和多个动作。",
    "方法": "我们提出一种自动方法，利用多模态输入（如文本视频描述、字幕和单个视频帧）来建立高质量字幕的视频数据集。具体来说，我们从公开可用的HD-VILA-100M数据集中筛选出3.8M高分辨率视频，将它们分割成语义一致的视频剪辑，并应用多个跨模态教师模型为每个视频获取字幕。接着，我们在一个小的子集上微调一个检索模型，该子集中每个视频的最佳字幕是手动选出的，然后在整个数据集上使用该模型选择最佳字幕作为注释。",
    "结果": "我们获得了70M个视频与高质量文本字幕配对的数据集，命名为Panda-70M。我们展示了该数据集在三个下游任务上的价值：视频字幕、视频和文本检索、以及文本驱动的视频生成。在所有任务上，使用所提数据训练的模型在大多数指标上得分显著更好。"
  },
  "summary_cn": "数据和标注的质量设定了下游模型的质量上限。虽然存在大量的文本语料库和图文对，但是收集高质量的视频-文本数据要困难得多。首先，手动标注更耗时，因为它要求标注者观看整个视频。其次，视频具有时间维度，由几个场景堆叠在一起，展示多个动作。因此，为了建立一个带有高质量标题的视频数据集，我们提出了一种自动方法，利用多模态输入，如文本视频描述、字幕和单个视频帧。具体来说，我们从公开可用的HD-VILA-100M数据集中策划了3.8M高分辨率视频。然后，我们将它们分割成语义一致的视频剪辑，并应用多个跨模态教师模型为每个视频获取标题。接下来，我们在一个小子集上微调一个检索模型，其中每个视频的最佳标题是手动选出的，然后在整个数据集上使用该模型选择最佳标题作为注释。通过这种方式，我们获得了7000万个与高质量文本标题配对的视频。我们将这个数据集命名为Panda-70M。我们展示了所提出数据集在三个下游任务上的价值：视频标题生成、视频和文本检索以及文本驱动的视频生成。在所有任务的大多数指标上，训练在所提数据上的模型得分显著更好。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\"视频文本数据集\", \"自动标注\", \"跨模态学习\", \"视频字幕\", \"视频帧\", \"数据预处理\", \"视频描述\", \"视频检索\", \"文本驱动的视频生成\"]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "视频文本数据集",
      "自动标注",
      "跨模态学习",
      "视频字幕",
      "视频帧",
      "数据预处理",
      "视频描述",
      "视频检索",
      "文本驱动的视频生成"
    ]
  }
}