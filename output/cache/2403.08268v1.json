{
  "id": "2403.08268v1",
  "title": "Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts",
  "pdf_url": "http://arxiv.org/pdf/2403.08268v1",
  "raw_tldr": "动机\t尽管图像到视频的生成技术近期有所进步，但对于更好的可控性和局部动画的探索较少。现有的图像到视频方法大多不具备局部感知能力，倾向于移动整个场景，而人类艺术家可能需要控制不同对象或区域的运动。此外，当前的图像到视频方法要求用户不仅描述目标动作，还需提供冗余的帧内容详细描述，这两个问题阻碍了当前图像到视频工具的实际应用。\n方法\t本文提出了一个名为Follow-Your-Click的实用框架，通过简单的用户点击（指定要移动什么）和短动作提示（指定如何移动）来实现图像动画。技术上，我们提出了首帧遮罩策略，显著提高了视频生成质量，并配备了短动作提示数据集的动作增强模块，以提高模型的短提示跟随能力。为了进一步控制运动速度，我们提出了基于流的运动幅度控制，以更精确地控制目标运动的速度。\n结果\t我们的框架相较于之前的方法，提供了更简单且精确的用户控制和更好的生成性能。与7个基线（包括商业工具和研究方法）在8个指标上的广泛实验表明，我们的方法具有优越性。",
  "tldr": {
    "动机": "尽管图像到视频的生成技术近期有所进步，但对于更好的可控性和局部动画的探索较少。现有的图像到视频方法大多不具备局部感知能力，倾向于移动整个场景，而人类艺术家可能需要控制不同对象或区域的运动。此外，当前的图像到视频方法要求用户不仅描述目标动作，还需提供冗余的帧内容详细描述，这两个问题阻碍了当前图像到视频工具的实际应用。",
    "方法": "本文提出了一个名为Follow-Your-Click的实用框架，通过简单的用户点击（指定要移动什么）和短动作提示（指定如何移动）来实现图像动画。技术上，我们提出了首帧遮罩策略，显著提高了视频生成质量，并配备了短动作提示数据集的动作增强模块，以提高模型的短提示跟随能力。为了进一步控制运动速度，我们提出了基于流的运动幅度控制，以更精确地控制目标运动的速度。",
    "结果": "我们的框架相较于之前的方法，提供了更简单且精确的用户控制和更好的生成性能。与7个基线（包括商业工具和研究方法）在8个指标上的广泛实验表明，我们的方法具有优越性。"
  },
  "summary_cn": "尽管近期在图像到视频生成方面取得了一些进展，但对于更好的可控性和局部动画的探索却较少。大多数现有的图像到视频方法并不具备局部感知能力，往往会移动整个场景。然而，人类艺术家可能需要控制不同物体或区域的运动。此外，当前的图像到视频（I2V）方法不仅要求用户描述目标动作，还需要提供冗余的帧内容详细描述。这两个问题阻碍了当前I2V工具的实际应用。在本文中，我们提出了一个实用框架，名为“跟随你的点击”（Follow-Your-Click），通过简单的用户点击（指定要移动的对象）和短动作提示（指定如何移动）来实现图像动画。技术上，我们提出了首帧遮罩策略，显著提高了视频生成质量，并配备了一个短动作提示数据集的动作增强模块，以提高我们模型的短提示跟随能力。为了进一步控制运动速度，我们提出了基于流的运动幅度控制，以更精确地控制目标运动的速度。我们的框架相比于之前的方法，具有更简单而精确的用户控制和更好的生成性能。与7个基准（包括商业工具和研究方法）在8个指标上的广泛实验表明，我们的方法具有优越性。项目页面：https://follow-your-click.github.io/",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"CV\",\n  \"标签\": [\n    \"image-to-video generation\",\n    \"local animation\",\n    \"user interaction\",\n    \"video generation quality\",\n    \"motion control\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "CV",
    "标签": [
      "image-to-video generation",
      "local animation",
      "user interaction",
      "video generation quality",
      "motion control"
    ]
  }
}