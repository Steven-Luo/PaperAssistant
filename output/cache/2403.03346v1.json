{
  "id": "2403.03346v1",
  "title": "Enhancing Vision-Language Pre-training with Rich Supervisions",
  "pdf_url": "http://arxiv.org/pdf/2403.03346v1",
  "raw_tldr": "动机\t我们提出了一种新的视觉-语言模型预训练范式——强监督的屏幕截图预训练（S4），利用大规模网页截图渲染数据，解决了传统图像-文本对预训练中缺乏的视觉和文本线索问题。\n方法\t在S4中，我们利用HTML元素的树状结构层次和空间定位，精心设计了10个预训练任务，并使用大规模注释数据。这些任务模拟了不同领域的下游任务，且注释成本低廉。\n结果\t与当前的屏幕截图预训练目标相比，我们的创新预训练方法显著提高了图像到文本模型在九个不同且流行的下游任务中的性能——在表格检测上的改进高达76.1%，在小部件标题生成上至少提高了1%。",
  "tldr": {
    "动机": "我们提出了一种新的视觉-语言模型预训练范式——强监督的屏幕截图预训练（S4），利用大规模网页截图渲染数据，解决了传统图像-文本对预训练中缺乏的视觉和文本线索问题。",
    "方法": "在S4中，我们利用HTML元素的树状结构层次和空间定位，精心设计了10个预训练任务，并使用大规模注释数据。这些任务模拟了不同领域的下游任务，且注释成本低廉。",
    "结果": "与当前的屏幕截图预训练目标相比，我们的创新预训练方法显著提高了图像到文本模型在九个不同且流行的下游任务中的性能——在表格检测上的改进高达76.1%，在小部件标题生成上至少提高了1%。"
  },
  "summary_cn": "我们提出了一种新颖的预训练范式——强监督屏幕截图预训练（S4），用于视觉-语言模型，采用大规模网络屏幕截图渲染数据。使用网络屏幕截图可以解锁视觉和文本提示的宝库，这些提示在使用图像-文本对时不存在。在S4中，我们利用HTML元素固有的树状结构层次和空间定位，精心设计了10个预训练任务，这些任务具有大规模注释数据。这些任务类似于不同领域的下游任务，且注释成本低廉。我们证明，与当前的屏幕截图预训练目标相比，我们创新的预训练方法显著提高了图像到文本模型在九个不同且流行的下游任务中的性能——在表格检测上提高了高达76.1%，在小部件标题生成上至少提高了1%。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\"Vision-Language Models\", \"Pre-training\", \"Web Screenshots\", \"HTML\", \"Image-to-Text\"]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "Vision-Language Models",
      "Pre-training",
      "Web Screenshots",
      "HTML",
      "Image-to-Text"
    ]
  }
}