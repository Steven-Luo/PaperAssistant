{
  "id": "2402.15627v1",
  "raw_tldr": "动机\t我们提出了MegaScale的设计、实现和工程经验，这是一个用于在超过10,000 GPU规模上训练大型语言模型(LLMs)的生产系统。在这个规模上训练LLMs带来了前所未有的训练效率和稳定性挑战。\n方法\t我们采取全栈方法，跨模型块和优化器设计、计算与通信重叠、操作符优化、数据管道和网络性能调优等方面共同设计算法和系统组件。开发了一套诊断工具来监控系统组件和深层堆栈中的事件，识别根本原因，并推导出实现容错和缓解慢节点的有效技术。\n结果\tMegaScale在12,288 GPU上训练一个175B LLM模型时，实现了55.2%的模型FLOPs利用率(MFU)，与Megatron-LM相比，MFU提高了1.34倍。分享了在识别和修复故障及慢节点方面的操作经验。",
  "tldr": {
    "动机": "我们提出了MegaScale的设计、实现和工程经验，这是一个用于在超过10,000 GPU规模上训练大型语言模型(LLMs)的生产系统。在这个规模上训练LLMs带来了前所未有的训练效率和稳定性挑战。",
    "方法": "我们采取全栈方法，跨模型块和优化器设计、计算与通信重叠、操作符优化、数据管道和网络性能调优等方面共同设计算法和系统组件。开发了一套诊断工具来监控系统组件和深层堆栈中的事件，识别根本原因，并推导出实现容错和缓解慢节点的有效技术。",
    "结果": "MegaScale在12,288 GPU上训练一个175B LLM模型时，实现了55.2%的模型FLOPs利用率(MFU)，与Megatron-LM相比，MFU提高了1.34倍。分享了在识别和修复故障及慢节点方面的操作经验。"
  },
  "summary_cn": "我们在本文中介绍了MegaScale的设计、实现和工程经验，这是一个用于在超过10,000个GPU规模上训练大型语言模型（LLMs）的生产系统。在这种规模上训练LLMs带来了前所未有的训练效率和稳定性挑战。我们采取了全栈方法，跨模型块和优化器设计、计算与通信重叠、操作符优化、数据管道以及网络性能调优等方面共同设计算法和系统组件。鉴于LLM训练任务的长期性，维持整个训练过程的高效率（即稳定性）是生产中的一个重要考虑因素。许多困难的稳定性问题只有在大规模时才会显现，深入的可观测性是解决这些问题的关键。我们开发了一套诊断工具来监控系统组件和深层栈中的事件，识别根本原因，并推导出有效技术以实现容错和缓解滞后者。MegaScale在12,288个GPU上训练一个175B LLM模型时，实现了55.2%的模型FLOPs利用率（MFU），与Megatron-LM相比，MFU提高了1.34倍。我们分享了在识别和修复故障及滞后者方面的操作经验。我们希望通过阐述问题并从系统角度分享我们的经验，这项工作能激发未来LLM系统研究的灵感。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"Machine Learning\",\n  \"标签\": [\n    \"large language models\",\n    \"GPU\",\n    \"training efficiency\",\n    \"system design\",\n    \"fault tolerance\",\n    \"model FLOPs utilization\",\n    \"Megatron-LM\"\n  ]\n}\n```",
  "tag_info": {
    "主要领域": "Machine Learning",
    "标签": [
      "large language models",
      "GPU",
      "training efficiency",
      "system design",
      "fault tolerance",
      "model FLOPs utilization",
      "Megatron-LM"
    ]
  }
}