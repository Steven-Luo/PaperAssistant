{
  "id": "2403.15371v1",
  "title": "Can large language models explore in-context?",
  "pdf_url": "http://arxiv.org/pdf/2403.15371v1",
  "raw_tldr": "动机\t探索当代大型语言模型（LLMs）在没有训练干预的情况下，参与探索的程度，这是强化学习和决策制定的核心能力。\n方法\t在简单的多臂老虎机环境中将LLMs作为代理部署，完全在上下文中指定环境描述和交互历史，即在LLM提示内进行实验，尝试了GPT-3.5、GPT-4和Llama2，使用多种提示设计。\n结果\t在我们的所有实验中，只有一种配置产生了令人满意的探索行为：带有思维链推理和外部总结的交互历史的GPT-4，呈现为充分的统计信息；所有其他配置都没有产生稳健的探索行为，包括那些带有思维链推理但未总结历史的配置。",
  "tldr": {
    "动机": "探索当代大型语言模型（LLMs）在没有训练干预的情况下，参与探索的程度，这是强化学习和决策制定的核心能力。",
    "方法": "在简单的多臂老虎机环境中将LLMs作为代理部署，完全在上下文中指定环境描述和交互历史，即在LLM提示内进行实验，尝试了GPT-3.5、GPT-4和Llama2，使用多种提示设计。",
    "结果": "在我们的所有实验中，只有一种配置产生了令人满意的探索行为：带有思维链推理和外部总结的交互历史的GPT-4，呈现为充分的统计信息；所有其他配置都没有产生稳健的探索行为，包括那些带有思维链推理但未总结历史的配置。"
  },
  "summary_cn": "我们研究了当代大型语言模型（LLMs）在探索方面的程度，这是强化学习和决策制定中的一项核心能力。我们关注的是现有LLMs的原生性能，而不是经过训练干预的性能。我们将LLMs作为代理部署在简单的多臂老虎机环境中，完全在上下文中指定环境描述和交互历史，即在LLM提示内。我们使用GPT-3.5、GPT-4和Llama2进行了实验，采用了多种提示设计，发现这些模型在没有重大干预的情况下不会稳健地进行探索：i) 在我们所有的实验中，只有一个配置产生了令人满意的探索行为：带有思维链推理和外部总结的交互历史的GPT-4，以充分统计量的形式呈现；ii) 所有其他配置都没有产生稳健的探索行为，包括那些带有思维链推理但历史未总结的配置。尽管这些发现可以被积极地解释，但它们表明，外部总结——在更复杂的设置中可能不可能——对于从LLM代理获得理想行为是重要的。我们得出结论，可能需要非平凡的算法干预，如微调或数据集策划，以赋能基于LLM的复杂环境中的决策制定代理。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"Machine Learning\",\n  \"子领域\": \"Reinforcement Learning, Large Language Models (LLMs)\",\n  \"标签\": [\"探索行为\", \"多臂老虎机\", \"GPT-3.5\", \"GPT-4\", \"Llama2\", \"链式思考\", \"外部总结\", \"决策制定\", \"算法干预\", \"微调\", \"数据集策划\"]\n}\n```",
  "tag_info": {
    "主要领域": "Machine Learning",
    "子领域": "Reinforcement Learning, Large Language Models (LLMs)",
    "标签": [
      "探索行为",
      "多臂老虎机",
      "GPT-3.5",
      "GPT-4",
      "Llama2",
      "链式思考",
      "外部总结",
      "决策制定",
      "算法干预",
      "微调",
      "数据集策划"
    ]
  }
}