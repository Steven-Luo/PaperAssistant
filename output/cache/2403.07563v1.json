{
  "id": "2403.07563v1",
  "title": "Learning Generalizable Feature Fields for Mobile Manipulation",
  "pdf_url": "http://arxiv.org/pdf/2403.07563v1",
  "raw_tldr": "动机\t移动操控中的一个开放性问题是如何以统一的方式表示对象和场景，以便机器人既可以用它来导航环境，也可以用来操纵对象。后者需要捕捉复杂的几何形状同时理解细粒度的语义，而前者涉及捕捉到广阔物理尺度内固有的复杂性。\n方法\t我们提出了GeFF（Generalizable Feature Fields），一个场景级别的可泛化神经特征场，作为导航和操纵的统一表示，能够实时执行。为此，我们将生成新视图合成视为预训练任务，然后通过CLIP特征蒸馏将得到的丰富场景先验与自然语言对齐。\n结果\t通过在装备有操纵器的四足机器人上部署GeFF，我们展示了这种方法的有效性。我们评估了GeFF在对开放集对象的泛化能力以及在动态场景中执行开放词汇移动操纵时的运行时间。",
  "tldr": {
    "动机": "移动操控中的一个开放性问题是如何以统一的方式表示对象和场景，以便机器人既可以用它来导航环境，也可以用来操纵对象。后者需要捕捉复杂的几何形状同时理解细粒度的语义，而前者涉及捕捉到广阔物理尺度内固有的复杂性。",
    "方法": "我们提出了GeFF（Generalizable Feature Fields），一个场景级别的可泛化神经特征场，作为导航和操纵的统一表示，能够实时执行。为此，我们将生成新视图合成视为预训练任务，然后通过CLIP特征蒸馏将得到的丰富场景先验与自然语言对齐。",
    "结果": "通过在装备有操纵器的四足机器人上部署GeFF，我们展示了这种方法的有效性。我们评估了GeFF在对开放集对象的泛化能力以及在动态场景中执行开放词汇移动操纵时的运行时间。"
  },
  "summary_cn": "在移动操控领域，一个公开的问题是如何以统一的方式表示对象和场景，以便机器人既可以用它来导航环境，也可以用来操纵物体。后者需要捕捉复杂的几何形状同时理解细粒度的语义，而前者涉及到捕捉广阔物理尺度内固有的复杂性。在这项工作中，我们提出了GeFF（可泛化的特征场），一个场景级别的可泛化神经特征场，作为导航和操纵的统一表示，并且能够实时执行。为此，我们将生成新视角合成视为一个预训练任务，然后通过CLIP特征蒸馏将得到的丰富场景先验与自然语言对齐。我们通过在装备有操纵器的四足机器人上部署GeFF来证明这种方法的有效性。我们评估了GeFF在动态场景中执行开放词汇移动操纵时对开放集对象的泛化能力以及运行时间。",
  "tag_info_raw": "```json\n{\n  \"主要领域\": \"多模态\",\n  \"标签\": [\"移动操纵\", \"统一表示\", \"实时性能\", \"场景理解\", \"自然语言处理\", \"特征蒸馏\", \"机器人\", \"开放词汇操作\"]\n}\n```",
  "tag_info": {
    "主要领域": "多模态",
    "标签": [
      "移动操纵",
      "统一表示",
      "实时性能",
      "场景理解",
      "自然语言处理",
      "特征蒸馏",
      "机器人",
      "开放词汇操作"
    ]
  }
}